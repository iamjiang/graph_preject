{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### run the following script in the terminal\n",
    "# python -m pip config set global.index-url https://PLV3106:${ARTIFACTORY_KEY}@repo.usaa.com/api/pypi/usaa-pypi-xray/simple\n",
    "### install the following package\n",
    "#!pip install --upgrade pip\n",
    "#!pip install --quiet tqdm==4.33.0 \n",
    "# !pip install --quiet torch==1.6.0 --index-url https://repo.usaa.com/artifactory/api/pypi/usaa-pypi-eval/simple --trusted-host repo.usaa.com\n",
    "# !pip install --quiet category-encoders==2.2.2\n",
    "#!pip install /mnt/dgl_cu102-0.6.0-cp36-cp36m-manylinux1_x86_64.whl\n",
    "#!pip install catboost==0.25.1\n",
    "# !pip install --quiet scikit-learn==0.24.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm\n",
    "tqdm().pandas()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "# os.environ['OMP_NUM_THREADS']=1\n",
    "# export OMP_NUM_THREADS=1\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Dropout, ELU, Sequential, Linear, ReLU\n",
    "\n",
    "import dgl\n",
    "from dgl import edge_subgraph\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "\n",
    "import bgnn_cpu\n",
    "import bgnn_gpu\n",
    "import bgnn_gpu_LGB\n",
    "import models\n",
    "import utils\n",
    "\n",
    "from category_encoders import CatBoostEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn\n",
    "# print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(X, train_mask, val_mask, test_mask):\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    A = X.to_numpy(copy=True)\n",
    "    A[train_mask] = min_max_scaler.fit_transform(A[train_mask])\n",
    "    A[val_mask + test_mask] = min_max_scaler.transform(A[val_mask + test_mask])\n",
    "    return pd.DataFrame(A, columns=X.columns).astype(float)\n",
    "\n",
    "def replace_na(X, train_mask):\n",
    "    if X.isna().any().any():\n",
    "        return X.fillna(X.iloc[train_mask].min() - 1)\n",
    "    return X\n",
    "\n",
    "def encode_cat_features(X, y, cat_features, train_mask, val_mask, test_mask):\n",
    "    enc = CatBoostEncoder()\n",
    "    A = X.to_numpy(copy=True)\n",
    "    b = y.to_numpy(copy=True)\n",
    "    A[np.ix_(train_mask, cat_features)] = enc.fit_transform(A[np.ix_(train_mask, cat_features)], b[train_mask])\n",
    "    A[np.ix_(val_mask + test_mask, cat_features)] = enc.transform(A[np.ix_(val_mask + test_mask, cat_features)])\n",
    "    A = A.astype(float)\n",
    "    return pd.DataFrame(A, columns=X.columns)\n",
    "\n",
    "\n",
    "def lift_gain_eval(logit,label,topk):\n",
    "    DF=pd.DataFrame(columns=[\"pred_score\",\"actual_label\"])\n",
    "    DF[\"pred_score\"]=logit\n",
    "    DF[\"actual_label\"]=label\n",
    "    DF.sort_values(by=\"pred_score\", ascending=False, inplace=True)\n",
    "    gain={}\n",
    "    for p in topk:\n",
    "        N=math.ceil(int(DF.shape[0]*p))\n",
    "        DF2=DF.nlargest(N,\"pred_score\",keep=\"first\")\n",
    "        gain[str(int(p*100))+\"%\"]=round(DF2.actual_label.sum()/(DF.actual_label.sum()),2)\n",
    "    return gain\n",
    "\n",
    "\n",
    "def get_class_count_weight(y,n_classes):\n",
    "    classes_count=[]\n",
    "    weight=[]\n",
    "    for i in range(n_classes):\n",
    "        count=np.sum(y.squeeze()==i)\n",
    "        classes_count.append(count)\n",
    "        weight.append(len(y)/(n_classes*count))\n",
    "    return classes_count,weight\n",
    "\n",
    "\n",
    "def eval_loop_func(model, loader, labels, device, loss_weight, num_classes):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    losses=[]\n",
    "    for input_nodes_raw, seeds, blocks in tqdm(loader, position=0, leave=True):\n",
    "        blocks = [blk.to(device) for blk in blocks]\n",
    "        seeds = seeds.to(device)\n",
    "        \n",
    "        input_nodes={}\n",
    "        input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "        input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "\n",
    "        lbl = labels[seeds].squeeze().to(device)\n",
    "        \n",
    "        with th.no_grad():\n",
    "            logits,h = model(input_nodes,blocks)\n",
    "            if loss_weight is None:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes), lbl.to(device))\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes), lbl.to(device),weight=loss_weight.float())        \n",
    "            losses.append(loss.item())\n",
    "        fin_targets.append(lbl.cpu().detach().numpy())\n",
    "        fin_outputs.append(logits.cpu().detach().numpy())\n",
    "    return np.concatenate(fin_outputs), np.concatenate(fin_targets), losses\n",
    "\n",
    "\n",
    "def evaluate(target, predicted):\n",
    "    true_label_mask=[1 if (np.argmax(x)-target[i])==0 else 0 for i,x in enumerate(predicted)]\n",
    "    nb_prediction=len(true_label_mask)\n",
    "    true_prediction=sum(true_label_mask)\n",
    "    false_prediction=nb_prediction-true_prediction\n",
    "    accuracy=true_prediction/nb_prediction\n",
    "    \n",
    "    precision, recall, fscore, support = precision_recall_fscore_support(target, predicted.argmax(axis=1))\n",
    "    auc = roc_auc_score(target.ravel(), th.sigmoid(th.from_numpy(predicted))[:,1].numpy().ravel())\n",
    "    \n",
    "    prec,rec,_ = precision_recall_curve(target.ravel(), th.sigmoid(th.from_numpy(predicted))[:,1].numpy().ravel())\n",
    "    \n",
    "    pr_auc=auc_score(rec,prec)\n",
    "    \n",
    "    arg1=predicted[:,1]\n",
    "    arg2=target\n",
    "    gain = lift_gain_eval(arg1,arg2,topk=[0.01,0.05,0.10])\n",
    "    \n",
    "    return {\n",
    "        \"nb_example\":len(target),\n",
    "        \"true_prediction\":true_prediction,\n",
    "        \"false_prediction\":false_prediction,\n",
    "        \"accuracy\":accuracy,\n",
    "        \"precision\":precision[1], \n",
    "        \"recall\":recall[1], \n",
    "        \"f1_score\":fscore[1],\n",
    "        \"AUC\":auc,\n",
    "        \"pr_auc\":pr_auc,\n",
    "        \"GAIN\":gain\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 16.0569 seconds to load graph\n"
     ]
    }
   ],
   "source": [
    "KG_dir=\"/workspace/cjiang/eagle_project/CAP_graph/BGNN/\"\n",
    "\n",
    "start=time.time()\n",
    "with open(os.path.join(KG_dir,'homo_graph'), 'rb') as f:\n",
    "    G, binary_label, train_mask,val_mask, test_mask = pickle.load(f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to load graph\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sampling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Node_types:  ['_N']\n",
      "Edge_types:  ['_E']\n",
      "**************************************************\n",
      "Canonical Etypes of Graph is:\n",
      "\n",
      "_N                  _E                  _N                  \n",
      "**************************************************\n",
      "number of ntype=_N                    8,359          \n",
      "**************************************************\n",
      "Total number of nodes is 8,359\n",
      "**************************************************\n",
      "number of etype=_E                    5,000          \n",
      "**************************************************\n",
      "Total number of edges is 5,000\n",
      "**************************************************\n",
      "**************************************************\n",
      "The attributes for the node type=_N\n",
      "**************************************************\n",
      "usaayr                                  torch.Size([8359, 1])\n",
      "AGE_BAND                                torch.Size([8359, 1])\n",
      "ORIGEL                                  torch.Size([8359, 1])\n",
      "ELIG2                                   torch.Size([8359, 1])\n",
      "cmpyelig                                torch.Size([8359, 1])\n",
      "SEX                                     torch.Size([8359, 1])\n",
      "MARST                                   torch.Size([8359, 1])\n",
      "PERSST                                  torch.Size([8359, 1])\n",
      "DEATHSDT                                torch.Size([8359, 1])\n",
      "BRANCH                                  torch.Size([8359, 1])\n",
      "MILST                                   torch.Size([8359, 1])\n",
      "MLIST_OrigStat                          torch.Size([8359, 1])\n",
      "enl1stsdt                               torch.Size([8359, 1])\n",
      "COMMSDT                                 torch.Size([8359, 1])\n",
      "ENLPAYGD                                torch.Size([8359, 1])\n",
      "ACTCORP                                 torch.Size([8359, 1])\n",
      "STATE                                   torch.Size([8359, 1])\n",
      "Segment                                 torch.Size([8359, 1])\n",
      "_ID                                     torch.Size([8359])\n"
     ]
    }
   ],
   "source": [
    "G.ndata[\"binary_label\"]=binary_label\n",
    "G.ndata[\"train_mask\"]=train_mask\n",
    "G.ndata[\"val_mask\"]=val_mask\n",
    "G.ndata[\"test_mask\"]=test_mask\n",
    "\n",
    "dict_edges={}\n",
    "for etype in G.etypes:\n",
    "    dict_edges[etype]=torch.arange(G.num_edges(etype))[0:5000]\n",
    "g=dgl.edge_subgraph(G,dict_edges)\n",
    "\n",
    "# g=G\n",
    "\n",
    "binary_label=g.ndata.pop(\"binary_label\")\n",
    "train_mask=g.ndata.pop(\"train_mask\")\n",
    "val_mask=g.ndata.pop(\"val_mask\")\n",
    "test_mask=g.ndata.pop(\"test_mask\")\n",
    "\n",
    "utils.graph_show(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(append_gbdt_pred=True, backprop_per_epoch=5, batch_size=10240, dropout=0.2, fanout=None, gbdt_depth=6, gbdt_lr=0.01, gpu=0, h_dim=64, l2norm=0.001, layer_norm=True, loss_weight=True, low_mem=True, lr=0.001, n_epochs=1, num_bases=5, num_layers=1, num_mini_batch=8, out_dim=1, seed=101, task='classification', train_input_features=True, trees_per_epoch=5, use_self_loop=True, validation=True)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='BGNN')\n",
    "\n",
    "parser.add_argument(\"--task\", type=str, default=\"classification\")\n",
    "parser.add_argument(\"--h_dim\", type=int, default=128,help=\"number of hidden units\")\n",
    "parser.add_argument(\"--trees_per_epoch\", type=int, default=5)\n",
    "parser.add_argument(\"--gbdt_depth\", type=int, default=6)\n",
    "\n",
    "parser.add_argument(\"--backprop_per_epoch\", type=int, default=1)\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01,help=\"learning rate for GNN\")\n",
    "parser.add_argument(\"--gbdt_lr\", type=float, default=0.01,help=\"learning rate for GBDT\")\n",
    "parser.add_argument(\"--append_gbdt_pred\", default=True, action='store_true')\n",
    "parser.add_argument(\"--train_input_features\", default=True, action='store_true')\n",
    "\n",
    "parser.add_argument(\"--dropout\", type=float, default=0,\n",
    "        help=\"dropout probability\")\n",
    "parser.add_argument(\"--out_dim\", type=int, default=1,\n",
    "        help=\"output dimension\")\n",
    "parser.add_argument(\"--num_bases\", type=int, default=-1,\n",
    "        help=\"number of filter weight matrices, default: -1 [use all]\")\n",
    "parser.add_argument(\"--num_layers\", type=int, default=1,\n",
    "        help=\"number of propagation rounds\")\n",
    "parser.add_argument(\"-e\", \"--n_epochs\", type=int, default=1,\n",
    "        help=\"number of training epochs\")\n",
    "parser.add_argument(\"--l2norm\", type=float, default=0,\n",
    "        help=\"l2 norm coef\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0,help=\"gpu\")\n",
    "parser.add_argument(\"--use_self_loop\", default=True, action='store_true',\n",
    "        help=\"include self feature as a special relation\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=1024,\n",
    "        help=\"Mini-batch size. If -1, use full graph training.\")\n",
    "parser.add_argument(\"--num_mini_batch\", type=int, default=8,\n",
    "        help=\"Number of minibatch.\")\n",
    "parser.add_argument(\"--fanout\", type=int, default=None,\n",
    "        help=\"Fan-out of neighbor sampling.\")\n",
    "parser.add_argument(\"--validation\",  default=True,\n",
    "        help=\"set up validation .\")\n",
    "parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "        help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "parser.add_argument(\"--loss_weight\",  type=bool,default=True,  ## number of label=0/number of label=1\n",
    "        help=\"weight for unbalance data\")\n",
    "\n",
    "args,unknown=parser.parse_known_args()\n",
    "\n",
    "args.num_layers=1\n",
    "args.dropout=0.2\n",
    "args.lr=1e-3\n",
    "args.l2norm=1e-3\n",
    "args.num_bases=5\n",
    "args.h_dim=64\n",
    "args.low_mem=True\n",
    "args.layer_norm=True\n",
    "args.use_self_loop=True\n",
    "args.batch_size=1024*10\n",
    "args.backprop_per_epoch=5\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set    6,737     \n",
      "validation set  804       \n",
      "test set        818       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero(Tensor input, *, Tensor out)\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_idx=torch.nonzero(train_mask.squeeze()).squeeze().tolist()\n",
    "val_idx=torch.nonzero(val_mask.squeeze()).squeeze().tolist()\n",
    "test_idx=torch.nonzero(test_mask.squeeze()).squeeze().tolist()\n",
    "\n",
    "print('{:<15} {:<10,}'.format(\"Training set\",len(train_idx)))\n",
    "print('{:<15} {:<10,}'.format(\"validation set\",len(val_idx)))\n",
    "print('{:<15} {:<10,}'.format(\"test set\",len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list=[]\n",
    "for key, scheme in g.node_attr_schemes().items():\n",
    "    feat_list.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 3956.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaayr</th>\n",
       "      <th>AGE_BAND</th>\n",
       "      <th>ORIGEL</th>\n",
       "      <th>ELIG2</th>\n",
       "      <th>cmpyelig</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARST</th>\n",
       "      <th>PERSST</th>\n",
       "      <th>DEATHSDT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>MILST</th>\n",
       "      <th>MLIST_OrigStat</th>\n",
       "      <th>enl1stsdt</th>\n",
       "      <th>COMMSDT</th>\n",
       "      <th>ENLPAYGD</th>\n",
       "      <th>ACTCORP</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Segment</th>\n",
       "      <th>_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>28712</td>\n",
       "      <td>24917</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>28712</td>\n",
       "      <td>24917</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   usaayr  AGE_BAND  ORIGEL  ELIG2  cmpyelig  SEX  MARST  PERSST  DEATHSDT  \\\n",
       "0      29         5       0      0         1    1      2       0       326   \n",
       "1      55         4      26      3         0    2      5       0       326   \n",
       "\n",
       "   BRANCH  MILST  MLIST_OrigStat  enl1stsdt  COMMSDT  ENLPAYGD  ACTCORP  \\\n",
       "0       1      2               2      28712    24917        14        1   \n",
       "1       0      0               2      28712    24917        24        1   \n",
       "\n",
       "   STATE  Segment  _ID  \n",
       "0     32        1    0  \n",
       "1      9        2    2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X={}\n",
    "for i in tqdm(range(len(feat_list)),position=0, leave=True):\n",
    "    col=feat_list[i]\n",
    "    X[col]=g.ndata.pop(col).squeeze().tolist()\n",
    "    \n",
    "X=pd.DataFrame(X)    \n",
    "\n",
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y={}\n",
    "y['class']=binary_label.squeeze().tolist()\n",
    "y=pd.DataFrame(y)\n",
    "y['class'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X.columns:\n",
    "    X[col]=X[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_X = X.copy()\n",
    "normalizeFeatures = False\n",
    "replaceNa = True\n",
    "\n",
    "cat_features=np.arange(len(feat_list))\n",
    "\n",
    "if len(cat_features):\n",
    "    encoded_X = encode_cat_features(encoded_X, y, cat_features, train_idx, val_idx, test_idx)\n",
    "if normalizeFeatures:\n",
    "    encoded_X = normalize_features(encoded_X, train_idx, val_idx, test_idx)\n",
    "if replaceNa:\n",
    "    encoded_X = replace_na(encoded_X, train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usaayr</th>\n",
       "      <th>AGE_BAND</th>\n",
       "      <th>ORIGEL</th>\n",
       "      <th>ELIG2</th>\n",
       "      <th>cmpyelig</th>\n",
       "      <th>SEX</th>\n",
       "      <th>MARST</th>\n",
       "      <th>PERSST</th>\n",
       "      <th>DEATHSDT</th>\n",
       "      <th>BRANCH</th>\n",
       "      <th>MILST</th>\n",
       "      <th>MLIST_OrigStat</th>\n",
       "      <th>enl1stsdt</th>\n",
       "      <th>COMMSDT</th>\n",
       "      <th>ENLPAYGD</th>\n",
       "      <th>ACTCORP</th>\n",
       "      <th>STATE</th>\n",
       "      <th>Segment</th>\n",
       "      <th>_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.714116</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.428232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     usaayr  AGE_BAND    ORIGEL     ELIG2  cmpyelig       SEX     MARST  \\\n",
       "0  0.428232  0.428232  0.428232  0.428232  0.428232  0.428232  0.428232   \n",
       "1  0.428232  0.428232  0.428232  0.428232  0.428232  0.428232  0.428232   \n",
       "\n",
       "     PERSST  DEATHSDT    BRANCH     MILST  MLIST_OrigStat  enl1stsdt  \\\n",
       "0  0.428232  0.428232  0.428232  0.428232        0.428232   0.428232   \n",
       "1  0.714116  0.714116  0.428232  0.428232        0.714116   0.714116   \n",
       "\n",
       "    COMMSDT  ENLPAYGD   ACTCORP     STATE   Segment       _ID  \n",
       "0  0.428232  0.428232  0.428232  0.428232  0.428232  0.428232  \n",
       "1  0.714116  0.428232  0.714116  0.428232  0.428232  0.428232  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rels=torch.unique(g.edata['etype']).shape[0]\n",
    "\n",
    "out_dim=torch.unique(binary_label).shape[0]\n",
    "in_dim = out_dim + X.shape[1]\n",
    "\n",
    "dummy_model = models.EntityClassify(g,\n",
    "                       in_dim,\n",
    "                       out_dim,\n",
    "                       num_rels,\n",
    "                       args.num_bases,\n",
    "                       args.num_layers,\n",
    "                       args.dropout,\n",
    "                       args.use_self_loop,\n",
    "                       args.low_mem,\n",
    "                       args.layer_norm)\n",
    "\n",
    "# dummy_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total # of parameter is 1,934\n"
     ]
    }
   ],
   "source": [
    "print(\"The total # of parameter is {:,}\".format(sum([p.nelement() for p in dummy_model.parameters()]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight                                                       441            \n",
      "layers.0.h_bias                                                       21             \n",
      "layers.0.loop_weight                                                  441            \n",
      "layers.0.layer_norm_weight.weight                                     21             \n",
      "layers.0.layer_norm_weight.bias                                       21             \n",
      "layers.1.weight                                                       441            \n",
      "layers.1.h_bias                                                       21             \n",
      "layers.1.loop_weight                                                  441            \n",
      "layers.1.layer_norm_weight.weight                                     21             \n",
      "layers.1.layer_norm_weight.bias                                       21             \n",
      "classifier.weight                                                     42             \n",
      "classifier.bias                                                       2              \n"
     ]
    }
   ],
   "source": [
    "param_dict={n: p.nelement() for n, p in dummy_model.named_parameters()}\n",
    "for i,j in param_dict.items():\n",
    "    print(\"{:<70}{:<15,}\".format(i,j))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EntityClassify(\n",
       "  (layers): ModuleList(\n",
       "    (0): RelGraphConv(\n",
       "      (layer_norm_weight): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): RelGraphConv(\n",
       "      (layer_norm_weight): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=21, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### check cuda\n",
    "device=\"cpu\"\n",
    "# use_cuda=args.gpu>=0 and torch.cuda.is_available()\n",
    "# if use_cuda:\n",
    "#     torch.cuda.set_device(args.gpu)\n",
    "#     device='cuda:%d' % args.gpu\n",
    "print(device)\n",
    "dummy_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize BGNN model\n",
    "bgnn = bgnn_cpu.BGNNPredictor(dummy_model, \n",
    "                              device,\n",
    "                              task='classification',\n",
    "                              loss_fn=None,\n",
    "                              trees_per_epoch=args.trees_per_epoch,\n",
    "                              backprop_per_epoch=args.backprop_per_epoch,\n",
    "                              lr=args.lr,\n",
    "                              append_gbdt_pred=args.append_gbdt_pred,\n",
    "                              train_input_features=args.train_input_features,\n",
    "                              gbdt_depth=args.gbdt_depth,\n",
    "                              gbdt_lr=args.gbdt_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.90it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.69it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 44.89it/s]\n",
      " 10%|█         | 1/10 [00:03<00:28,  3.12s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.02it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.41it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 112.18it/s]\n",
      " 20%|██        | 2/10 [00:05<00:23,  2.91s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.11it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.22it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 15.21it/s]\n",
      " 30%|███       | 3/10 [00:08<00:19,  2.80s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 28.05it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.74it/s]\n",
      " 40%|████      | 4/10 [00:11<00:17,  2.98s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.34it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 26.94it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 124.11it/s]\n",
      " 50%|█████     | 5/10 [00:13<00:12,  2.58s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.32it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.97it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 65.55it/s]\n",
      " 60%|██████    | 6/10 [00:15<00:10,  2.54s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 24.95it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.46it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 61.39it/s]\n",
      " 70%|███████   | 7/10 [00:18<00:07,  2.62s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 29.16it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 14.73it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 74.09it/s]\n",
      " 80%|████████  | 8/10 [00:20<00:05,  2.60s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 33.69it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 27.78it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 32.73it/s]\n",
      " 90%|█████████ | 9/10 [00:22<00:02,  2.30s/it]/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 10.03it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.71it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/dgl/base.py:45: DGLWarning: Key word argument preserve_nodes is deprecated. Use relabel_nodes instead.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n",
      "100%|██████████| 1/1 [00:00<00:00, 80.78it/s]\n",
      "100%|██████████| 10/10 [00:24<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss at iteration 9: 0.077\n",
      "loading time is 24.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %pdb\n",
    "start=time.time()\n",
    "train_metric, val_metric, test_metric = bgnn.fit(g, encoded_X, y, train_idx, val_idx, test_idx,\\\n",
    "                   original_X = X, cat_features=cat_features,\\\n",
    "                   num_epochs=10, patience=5, metric_name='loss',\\\n",
    "                   fanout=args.fanout,num_layers=args.num_layers,batch_size=args.batch_size)\n",
    "\n",
    "end=time.time()\n",
    "print(\"loading time is {:0.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.08580104261636734,\n",
       " 'nb_example': 6737,\n",
       " 'true_prediction': 6720,\n",
       " 'false_prediction': 17,\n",
       " 'accuracy': 0.9974766216416803,\n",
       " 'precision': 0.9944827586206897,\n",
       " 'recall': 0.9970613656006914,\n",
       " 'AUC': 0.9999643661219003,\n",
       " 'pr_auc': 0.99995239625854,\n",
       " 'GAIN': {'1%': 0.02, '5%': 0.12, '10%': 0.23}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.07661468535661697,\n",
       " 'nb_example': 6737,\n",
       " 'true_prediction': 6722,\n",
       " 'false_prediction': 15,\n",
       " 'accuracy': 0.9977734896838355,\n",
       " 'precision': 0.9948275862068966,\n",
       " 'recall': 0.9974070872947277,\n",
       " 'AUC': 0.9999871322106862,\n",
       " 'pr_auc': 0.9999827845413412,\n",
       " 'GAIN': {'1%': 0.02, '5%': 0.12, '10%': 0.23}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.061647929251194,\n",
       " 'nb_example': 818,\n",
       " 'true_prediction': 818,\n",
       " 'false_prediction': 0,\n",
       " 'accuracy': 1.0,\n",
       " 'precision': 1.0,\n",
       " 'recall': 1.0,\n",
       " 'AUC': 1.0,\n",
       " 'pr_auc': 1.0,\n",
       " 'GAIN': {'1%': 0.02, '5%': 0.11, '10%': 0.22}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted= bgnn.predict(g, X, test_idx,args.fanout,args.num_layers,args.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EntityClassify(\n",
       "  (layers): ModuleList(\n",
       "    (0): RelGraphConv(\n",
       "      (layer_norm_weight): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): RelGraphConv(\n",
       "      (layer_norm_weight): LayerNorm((21,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=21, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### check cuda\n",
    "device=\"cpu\"\n",
    "use_cuda=args.gpu>=0 and torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(args.gpu)\n",
    "    device='cuda:%d' % args.gpu\n",
    "print(device)\n",
    "dummy_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize BGNN model\n",
    "bgnn = bgnn_gpu_LGB.BGNNPredictor(dummy_model, \n",
    "                              device,\n",
    "                              task='classification',\n",
    "                              loss_fn=None,\n",
    "                              trees_per_epoch=args.trees_per_epoch,\n",
    "                              backprop_per_epoch=args.backprop_per_epoch,\n",
    "                              lr=args.lr,\n",
    "                              append_gbdt_pred=args.append_gbdt_pred,\n",
    "                              train_input_features=args.train_input_features,\n",
    "                              gbdt_depth=args.gbdt_depth,\n",
    "                              gbdt_lr=args.gbdt_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"set\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-2d6d396d226e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0moriginal_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                    fanout=args.fanout,num_layers=args.num_layers,batch_size=args.batch_size)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/BGNN/sample/bgnn_gpu_LGB.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, graph, X, y, train_mask, val_mask, test_mask, original_X, cat_features, num_epochs, patience, metric_name, fanout, num_layers, batch_size)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;31m# gbdt part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             self.train_gbdt(gbdt_X_train, gbdt_y_train, cat_features, epoch,\n\u001b[0;32m--> 422\u001b[0;31m                             self.trees_per_epoch, gbdt_alpha)\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_node_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/BGNN/sample/bgnn_gpu_LGB.py\u001b[0m in \u001b[0;36mtrain_gbdt\u001b[0;34m(self, gbdt_X_train, gbdt_y_train, cat_features, epoch, gbdt_trees_per_epoch, gbdt_alpha)\u001b[0m\n\u001b[1;32m    133\u001b[0m                    gbdt_trees_per_epoch, gbdt_alpha):\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mepoch_gbdt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gbdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbdt_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdt_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdt_trees_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'classification'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_gbdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_gbdt_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/BGNN/sample/bgnn_gpu_LGB.py\u001b[0m in \u001b[0;36mfit_gbdt\u001b[0;34m(self, gbdt_X_train, gbdt_y_train, trees_per_epoch, epoch)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_gbdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdt_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdt_y_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrees_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mgbdt_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_gbdt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mgbdt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgbdt_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgbdt_y_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgbdt_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0meval_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     callbacks=callbacks, init_model=init_model)\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0;31m# concatenate metric from params (or default if not provided in params) and eval_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval_metrics_builtin\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metric'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"set\") to list"
     ]
    }
   ],
   "source": [
    "# %pdb\n",
    "start=time.time()\n",
    "train_metric, val_metric, test_metric = bgnn.fit(g, encoded_X, y, train_idx, val_idx, test_idx,\\\n",
    "                   original_X = X, cat_features=cat_features,\\\n",
    "                   num_epochs=10, patience=5, metric_name='loss',\\\n",
    "                   fanout=args.fanout,num_layers=args.num_layers,batch_size=args.batch_size)\n",
    "\n",
    "end=time.time()\n",
    "print(\"loading time is {:0.4f}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
