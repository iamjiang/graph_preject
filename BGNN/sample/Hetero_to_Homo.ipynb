{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is 1.6.0\n",
      "DGL version is 0.6.0\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save,load,savetxt,loadtxt,savez_compressed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook,tnrange\n",
    "tqdm.pandas(position=0, leave=True)\n",
    "import math \n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl import edge_subgraph\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "\n",
    "import functools\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(5.0,4.0)\n",
    "plt.rcParams['image.interpolation']='nearest'\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "import tsne_func\n",
    "print(\"torch version is {}\".format(th.__version__))\n",
    "print(\"DGL version is {}\".format(dgl.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 6.9107 seconds to load graph\n"
     ]
    }
   ],
   "source": [
    "KG_dir=\"/home/ubuntu/\"\n",
    "\n",
    "if os.path.isfile(\"/home/ubuntu/CAP_Graph_New\")==False:\n",
    "    !hdfs dfs -get /dz/dz_6104/disc.db/CAP_Graph_New  ~/CAP_Graph_New\n",
    "\n",
    "start=time.time()\n",
    "with open(os.path.join(KG_dir,'CAP_Graph_New'), 'rb') as f:\n",
    "    hg,multi_label,binary_label,\\\n",
    "    train_mask_multi_label,  val_mask_multi_label,  test_mask_multi_label,\\\n",
    "    train_mask_binary_label, val_mask_binary_label, test_mask_binary_label= pickle.load(f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to load graph\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg.nodes['usaanr'].data[\"LABEL\"]= binary_label\n",
    "hg.nodes['usaanr'].data[\"train_mask\"]= th.tensor( np.expand_dims(np.array(train_mask_binary_label), 1) )\n",
    "hg.nodes['usaanr'].data[\"val_mask\"]= th.tensor( np.expand_dims(np.array(val_mask_binary_label), 1) )\n",
    "hg.nodes['usaanr'].data[\"test_mask\"]= th.tensor( np.expand_dims(np.array(test_mask_binary_label), 1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg.edges['Parent'].data[\"etype\"]=th.zeros(hg.num_edges(\"Parent\"))\n",
    "hg.edges['Child'].data[\"etype\"]=th.ones(hg.num_edges(\"Child\"))\n",
    "hg.edges['Spouse'].data[\"etype\"]=th.ones(hg.num_edges(\"Spouse\"))*2\n",
    "hg.edges['Ex-Spouse'].data[\"etype\"]=th.ones(hg.num_edges(\"Ex-Spouse\"))*3\n",
    "hg.edges['Brother_Sister'].data[\"etype\"]=th.ones(hg.num_edges(\"Brother_Sister\"))*4\n",
    "hg.edges['Step-Parent'].data[\"etype\"]=th.ones(hg.num_edges(\"Step-Parent\"))*5\n",
    "hg.edges['Step-Child'].data[\"etype\"]=th.ones(hg.num_edges(\"Step-Child\"))*6\n",
    "hg.edges['Pers_rel_Other'].data[\"etype\"]=th.ones(hg.num_edges(\"Pers_rel_Other\"))*7\n",
    "hg.edges['SPONSOR'].data[\"etype\"]=th.ones(hg.num_edges(\"SPONSOR\"))*8\n",
    "hg.edges['SPONSEE'].data[\"etype\"]=th.ones(hg.num_edges(\"SPONSEE\"))*9\n",
    "hg.edges['AUTO_RELATED'].data[\"etype\"]=th.ones(hg.num_edges(\"AUTO_RELATED\"))*10\n",
    "hg.edges['Busi_rel_Other'].data[\"etype\"]=th.ones(hg.num_edges(\"Busi_rel_Other\"))*11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate norm for each edge type and store in edge\n",
    "for canonical_etype in hg.canonical_etypes:\n",
    "    u, v, eid = hg.all_edges(form='all', etype=canonical_etype)\n",
    "    _, inverse_index, count = th.unique(v, return_inverse=True, return_counts=True)\n",
    "    degrees = count[inverse_index]\n",
    "    norm = th.ones(eid.shape[0]).float() / degrees.float()\n",
    "    norm = norm.unsqueeze(1)\n",
    "    hg.edges[canonical_etype].data['norm'] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "usaanr_feat=[]\n",
    "for key, scheme in hg.node_attr_schemes(ntype=\"usaanr\").items():\n",
    "    usaanr_feat.append(key)\n",
    "# usaanr_feat=[x for x in usaanr_feat if x not in ['ZIPCD','AGE','train_mask','val_mask','test_mask']]\n",
    "\n",
    "# print()\n",
    "# print(\"The features associated with USAA Member are\\n \")\n",
    "# for i in usaanr_feat:\n",
    "#     print(i)\n",
    "\n",
    "g, ntype_count, etype_count=dgl.to_homogeneous(hg,ndata=usaanr_feat,edata=['norm','etype'],store_type=True,return_count=True)\n",
    "\n",
    "num_nodes=g.num_nodes()\n",
    "node_ids=th.arange(num_nodes)\n",
    "edge_norm=g.edata['norm']\n",
    "edge_type=g.edata['etype'].long()\n",
    "\n",
    "g.ndata['ntype']=g.ndata.pop(dgl.NTYPE)\n",
    "\n",
    "num_rels=g.edata['etype'].unique().max().item()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm\n",
      "etype\n"
     ]
    }
   ],
   "source": [
    "### Remove some features from edges \n",
    "_ID=g.edata.pop(\"_ID\")\n",
    "_TYPE=g.edata.pop(\"_TYPE\")\n",
    "\n",
    "for key, val in g.edge_attr_schemes().items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usaayr\n",
      "AGE_BAND\n",
      "ORIGEL\n",
      "ELIG2\n",
      "cmpyelig\n",
      "SEX\n",
      "MARST\n",
      "PERSST\n",
      "DEATHSDT\n",
      "BRANCH\n",
      "MILST\n",
      "MLIST_OrigStat\n",
      "enl1stsdt\n",
      "COMMSDT\n",
      "ENLPAYGD\n",
      "ACTCORP\n",
      "STATE\n",
      "Segment\n"
     ]
    }
   ],
   "source": [
    "### Remove some features from nodes so that the graph only contain the features used in the model\n",
    "zipcd=g.ndata.pop(\"ZIPCD\")\n",
    "AGE=g.ndata.pop(\"AGE\")\n",
    "train_mask=g.ndata.pop(\"train_mask\")\n",
    "val_mask=g.ndata.pop(\"val_mask\")\n",
    "test_mask=g.ndata.pop(\"test_mask\")\n",
    "_ID=g.ndata.pop(\"_ID\")\n",
    "ntype=g.ndata.pop(\"ntype\")\n",
    "LABEL=g.ndata.pop(\"LABEL\")\n",
    "\n",
    "for key, val in g.node_attr_schemes().items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### save graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/home/ubuntu/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 32.2126 seconds to save graph database\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "with open(os.path.join(data_dir,\"homo_graph\"),\"wb\") as f:\n",
    "    pickle.dump((g,LABEL,train_mask,val_mask, test_mask),f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to save graph database\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -put -f ~/homo_graph  /dz/dz_6104/disc.db/gnnexplainer/homo_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 7.0890 seconds to load graph database\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "with open(os.path.join(data_dir,\"homo_graph\"),\"rb\") as f:\n",
    "    g,LABEL,train_mask,val_mask, test_mask=pickle.load(f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to load graph database\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
