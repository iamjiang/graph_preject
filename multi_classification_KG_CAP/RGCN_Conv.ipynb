{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade --quiet pip\n",
    "# !pip install --quiet torch==1.6.0 --index-url https://repo.usaa.com/artifactory/api/pypi/usaa-pypi-eval/simple --trusted-host repo.usaa.com\n",
    "# !pip install --quiet /mnt/dgl_cu102-0.6.0-cp36-cp36m-manylinux1_x86_64.whl\n",
    "# !pip install --upgrade --quiet tqdm\n",
    "# !pip install --quiet tqdm==4.33.0 \n",
    "# !pip install --quiet scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is 1.6.0\n",
      "DGL version is 0.6.0\n",
      "sklean version is 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save,load,savetxt,loadtxt,savez_compressed\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook,tnrange\n",
    "tqdm.pandas(position=0, leave=True)\n",
    "import math \n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as Fn\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(5.0,4.0)\n",
    "plt.rcParams['image.interpolation']='nearest'\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "# import tsne_func\n",
    "print(\"torch version is {}\".format(th.__version__))\n",
    "print(\"DGL version is {}\".format(dgl.__version__))\n",
    "print(\"sklean version is {}\".format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "    th.cuda.manual_seed_all(seed)\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 8.8891 seconds to load graph\n"
     ]
    }
   ],
   "source": [
    "KG_dir=\"/home/ubuntu/\"\n",
    "\n",
    "if os.path.isfile(\"/home/ubuntu/CAP_Graph_07082021\")==False:\n",
    "    !hdfs dfs -get /dz/dz_6104/disc.db/CAP_Graph_07082021  ~/CAP_Graph_07082021\n",
    "\n",
    "start=time.time()\n",
    "with open(os.path.join(KG_dir,'CAP_Graph_07082021'), 'rb') as f:\n",
    "    G,multi_label,binary_label,\\\n",
    "    train_mask_multi_label,  val_mask_multi_label,  test_mask_multi_label,\\\n",
    "    train_mask_binary_label, val_mask_binary_label, test_mask_binary_label= pickle.load(f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to load graph\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Node_types:  ['usaanr']\n",
      "Edge_types:  ['AUTO_RELATED', 'Brother_Sister', 'Busi_rel_Other', 'Child', 'Ex-Spouse', 'Parent', 'Pers_rel_Other', 'SPONSEE', 'SPONSOR', 'Spouse', 'Step-Child', 'Step-Parent']\n",
      "**************************************************\n",
      "Canonical Etypes of Graph is:\n",
      "\n",
      "usaanr              AUTO_RELATED        usaanr              \n",
      "usaanr              Brother_Sister      usaanr              \n",
      "usaanr              Busi_rel_Other      usaanr              \n",
      "usaanr              Child               usaanr              \n",
      "usaanr              Ex-Spouse           usaanr              \n",
      "usaanr              Parent              usaanr              \n",
      "usaanr              Pers_rel_Other      usaanr              \n",
      "usaanr              SPONSEE             usaanr              \n",
      "usaanr              SPONSOR             usaanr              \n",
      "usaanr              Spouse              usaanr              \n",
      "usaanr              Step-Child          usaanr              \n",
      "usaanr              Step-Parent         usaanr              \n",
      "**************************************************\n",
      "number of ntype=usaanr                25,668,504     \n",
      "**************************************************\n",
      "Total number of nodes is 25,668,504\n",
      "**************************************************\n",
      "number of etype=AUTO_RELATED          7,947,060      \n",
      "number of etype=Brother_Sister        651,444        \n",
      "number of etype=Busi_rel_Other        1,039,214      \n",
      "number of etype=Child                 11,765,795     \n",
      "number of etype=Ex-Spouse             3,877,972      \n",
      "number of etype=Parent                11,765,795     \n",
      "number of etype=Pers_rel_Other        2,012,514      \n",
      "number of etype=SPONSEE               16,775,141     \n",
      "number of etype=SPONSOR               16,775,141     \n",
      "number of etype=Spouse                16,016,119     \n",
      "number of etype=Step-Child            1,240,193      \n",
      "number of etype=Step-Parent           1,240,193      \n",
      "**************************************************\n",
      "Total number of edges is 91,106,581\n",
      "**************************************************\n",
      "**************************************************\n",
      "The attributes for the node type=usaanr\n",
      "**************************************************\n",
      "usaayr                                  torch.Size([25668504, 1])\n",
      "AGE                                     torch.Size([25668504, 1])\n",
      "AGE_BAND                                torch.Size([25668504, 1])\n",
      "ORIGEL                                  torch.Size([25668504, 1])\n",
      "ELIG2                                   torch.Size([25668504, 1])\n",
      "cmpyelig                                torch.Size([25668504, 1])\n",
      "SEX                                     torch.Size([25668504, 1])\n",
      "MARST                                   torch.Size([25668504, 1])\n",
      "PERSST                                  torch.Size([25668504, 1])\n",
      "DEATHSDT                                torch.Size([25668504, 1])\n",
      "BRANCH                                  torch.Size([25668504, 1])\n",
      "MILST                                   torch.Size([25668504, 1])\n",
      "MLIST_OrigStat                          torch.Size([25668504, 1])\n",
      "enl1stsdt                               torch.Size([25668504, 1])\n",
      "COMMSDT                                 torch.Size([25668504, 1])\n",
      "ENLPAYGD                                torch.Size([25668504, 1])\n",
      "ACTCORP                                 torch.Size([25668504, 1])\n",
      "STATE                                   torch.Size([25668504, 1])\n",
      "Segment                                 torch.Size([25668504, 1])\n",
      "ZIPCD                                   torch.Size([25668504, 1])\n"
     ]
    }
   ],
   "source": [
    "utils.graph_show(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The features associated with USAA Member are\n",
      " \n",
      "usaayr\n",
      "AGE_BAND\n",
      "ORIGEL\n",
      "ELIG2\n",
      "cmpyelig\n",
      "SEX\n",
      "MARST\n",
      "BRANCH\n",
      "MILST\n",
      "MLIST_OrigStat\n",
      "ENLPAYGD\n",
      "ACTCORP\n",
      "STATE\n",
      "Segment\n"
     ]
    }
   ],
   "source": [
    "feat_list=[]\n",
    "for key, scheme in G.node_attr_schemes(ntype=\"usaanr\").items():\n",
    "    feat_list.append(key)\n",
    "feat_list=[x for x in feat_list if x not in ['ZIPCD','AGE','enl1stsdt','COMMSDT','PERSST','DEATHSDT']]\n",
    "\n",
    "print()\n",
    "print(\"The features associated with USAA Member are\\n \")\n",
    "for i in feat_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USAA Members Features Embedding\n",
    "class USAANR_Embedding(nn.Module):\n",
    "    def __init__(self,G,feature_size, feat_list):\n",
    "        super(USAANR_Embedding,self).__init__()\n",
    "        self.G=G.to(device)\n",
    "        self.feature_size=feature_size\n",
    "        self.feat_list=feat_list\n",
    "        ## Embedding matrices for features of nodes.\n",
    "        self.emb = nn.ModuleDict()\n",
    "        \n",
    "        for i,col in enumerate(self.feat_list):\n",
    "            self.emb[col]=nn.Embedding(G.nodes['usaanr'].data[col].max().item()+1, feature_size)\n",
    "    \n",
    "    def forward(self,nid):\n",
    "        nid=nid.to(device)\n",
    "        extra_repr=[]\n",
    "        \n",
    "        for i,col in enumerate(self.feat_list):\n",
    "            ndata=self.G.nodes['usaanr'].data[col]\n",
    "            extra_repr.append(self.emb[col](ndata[nid]).squeeze(1))\n",
    "        return th.stack(extra_repr, 0).sum(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelGraphConvLayer(nn.Module):\n",
    "    r\"\"\"Relational graph convolution layer.\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_feat : int\n",
    "        Input feature size.\n",
    "    out_feat : int\n",
    "        Output feature size.\n",
    "    rel_names : list[str]\n",
    "        Relation names.\n",
    "    num_bases : int, optional\n",
    "        Number of bases. If is none, use number of relations. Default: None.\n",
    "    weight : bool, optional\n",
    "        True if a linear layer is applied after message passing. Default: True\n",
    "    bias : bool, optional\n",
    "        True if bias is added. Default: True\n",
    "    activation : callable, optional\n",
    "        Activation function. Default: None\n",
    "    self_loop : bool, optional\n",
    "        True to include self loop message. Default: False\n",
    "    dropout : float, optional\n",
    "        Dropout rate. Default: 0.0\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 in_feat,\n",
    "                 out_feat,\n",
    "                 rel_names,\n",
    "                 num_bases,\n",
    "                 *,\n",
    "                 weight=True,\n",
    "                 bias=True,\n",
    "                 activation=None,\n",
    "                 self_loop=False,\n",
    "                 dropout=0.0):\n",
    "        super(RelGraphConvLayer, self).__init__()\n",
    "        self.in_feat = in_feat\n",
    "        self.out_feat = out_feat\n",
    "        self.rel_names = rel_names\n",
    "        self.num_bases = num_bases\n",
    "        self.bias = bias\n",
    "        self.activation = activation\n",
    "        self.self_loop = self_loop\n",
    "        self.conv = dglnn.HeteroGraphConv({\n",
    "                rel : dglnn.GraphConv(in_feat, out_feat, norm=\"both\", weight=False, bias=False)\n",
    "                for rel in rel_names\n",
    "            })\n",
    "        self.use_weight = weight\n",
    "        self.use_basis = num_bases < len(self.rel_names) and weight\n",
    "        if self.use_weight:\n",
    "            if self.use_basis:\n",
    "                self.basis = dglnn.WeightBasis((in_feat, out_feat), num_bases, len(self.rel_names))\n",
    "            else:\n",
    "                self.weight = nn.Parameter(th.Tensor(len(self.rel_names), in_feat, out_feat))\n",
    "                nn.init.xavier_uniform_(self.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        # bias\n",
    "        if bias:\n",
    "            self.h_bias = nn.Parameter(th.Tensor(out_feat))\n",
    "            nn.init.zeros_(self.h_bias)\n",
    "        # weight for self loop\n",
    "        if self.self_loop:\n",
    "            self.loop_weight = nn.Parameter(th.Tensor(in_feat, out_feat))\n",
    "            nn.init.xavier_uniform_(self.loop_weight,\n",
    "                                    gain=nn.init.calculate_gain('relu'))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, g, inputs):\n",
    "        \"\"\"Forward computation\n",
    "        Parameters\n",
    "        ----------\n",
    "        g : DGLHeteroGraph\n",
    "            Input graph.\n",
    "        inputs : dict[str, torch.Tensor]\n",
    "            Node feature for each node type.\n",
    "        Returns\n",
    "        -------\n",
    "        dict[str, torch.Tensor]\n",
    "            New node features for each node type.\n",
    "        \"\"\"\n",
    "        g = g.local_var()\n",
    "        if self.use_weight:\n",
    "            weight = self.basis() if self.use_basis else self.weight\n",
    "            wdict = {self.rel_names[i] : {'weight' : w.squeeze(0)}\n",
    "                     for i, w in enumerate(th.split(weight, 1, dim=0))}\n",
    "        else:\n",
    "            wdict = {}\n",
    "        if g.is_block:\n",
    "            inputs_src = inputs\n",
    "            inputs_dst = {k: v[:g.number_of_dst_nodes(k)] for k, v in inputs.items()}\n",
    "        else:\n",
    "            inputs_src = inputs_dst = inputs\n",
    "        hs = self.conv(g, inputs, mod_kwargs=wdict)\n",
    "        def _apply(ntype, h):\n",
    "            if self.self_loop:\n",
    "                h = h + th.matmul(inputs_dst[ntype], self.loop_weight)\n",
    "            if self.bias:\n",
    "                h = h + self.h_bias\n",
    "            if self.activation:\n",
    "                h = self.activation(h)\n",
    "            return self.dropout(h)\n",
    "        return {ntype : _apply(ntype, h) for ntype, h in hs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity_Classify(nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 feat_list,\n",
    "                 h_dim,\n",
    "                 out_dim,\n",
    "                 num_bases,\n",
    "#                  embed_layer,\n",
    "                 num_hidden_layers=1,\n",
    "                 dropout=0,\n",
    "                 use_self_loop=False):\n",
    "        super(Entity_Classify, self).__init__()\n",
    "        self.g = g\n",
    "        self.feat_list=feat_list\n",
    "        self.h_dim = h_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.rel_names = list(set(g.etypes))\n",
    "#         self.num_bases = None if num_bases < 0 else num_bases\n",
    "        if num_bases < 0 or num_bases > len(self.rel_names):\n",
    "            self.num_bases = len(self.rel_names)\n",
    "        else:\n",
    "            self.num_bases = num_bases\n",
    "            \n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.dropout = dropout\n",
    "        self.use_self_loop = use_self_loop\n",
    "        \n",
    "#         self.node_embed={}\n",
    "        self.node_embed=nn.ModuleDict()\n",
    "        self.node_embed['usaanr'] = USAANR_Embedding(self.g,self.h_dim,self.feat_list)\n",
    "#         self.node_embed['zipcode'] = Zipcode_Embedding(self.g,self.h_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        #i2h\n",
    "        self.layers.append(RelGraphConvLayer(\n",
    "                    self.h_dim, self.h_dim, self.rel_names,\n",
    "                    self.num_bases, activation=F.relu, self_loop=self.use_self_loop,\n",
    "                    dropout=self.dropout, weight=True))\n",
    "        # h2h\n",
    "        if self.num_hidden_layers>1:\n",
    "            for i in range(0,self.num_hidden_layers-1):\n",
    "                self.layers.append(RelGraphConvLayer(\n",
    "                    self.h_dim, self.h_dim, self.rel_names,\n",
    "                    self.num_bases, activation=F.relu, self_loop=self.use_self_loop,\n",
    "                    dropout=self.dropout))\n",
    "        # h2o\n",
    "#         self.layers.append(RelGraphConvLayer(\n",
    "#             self.h_dim, self.out_dim, self.rel_names, \n",
    "#             self.num_bases, activation=partial(F.softmax, dim=1),\n",
    "#             self_loop=self.use_self_loop))\n",
    "        self.classifier = nn.Linear(self.h_dim, self.out_dim)\n",
    "    \n",
    "    def forward(self, input_nodes, blocks=None):\n",
    "        H={}\n",
    "        for ntype, nid in input_nodes.items():\n",
    "            nid = input_nodes[ntype]\n",
    "            H[ntype] = self.node_embed[ntype](nid)\n",
    "        if blocks is None:\n",
    "            for layer in self.layers:\n",
    "                H = layer(self.g, H)\n",
    "        else:\n",
    "            for layer, block in zip(self.layers, blocks):\n",
    "                H = layer(block, H)\n",
    "        output = self.classifier(H[\"usaanr\"])\n",
    "    \n",
    "        return output, H[\"usaanr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_gain_eval(logit,label,topk):\n",
    "    DF=pd.DataFrame(columns=[\"pred_score\",\"actual_label\"])\n",
    "    DF[\"pred_score\"]=logit\n",
    "    DF[\"actual_label\"]=label\n",
    "    DF.sort_values(by=\"pred_score\", ascending=False, inplace=True)\n",
    "    gain={}\n",
    "    for p in topk:\n",
    "        N=math.ceil(int(DF.shape[0]*p))\n",
    "        DF2=DF.nlargest(N,\"pred_score\",keep=\"first\")\n",
    "        gain[str(int(p*100))+\"%\"]=round(DF2.actual_label.sum()/(DF.actual_label.sum()),2)\n",
    "    return gain\n",
    "\n",
    "def get_class_count_weight(y,n_classes):\n",
    "    classes_count=[]\n",
    "    weight=[]\n",
    "    for i in range(n_classes):\n",
    "        count=np.sum(y.squeeze()==i)\n",
    "        classes_count.append(count)\n",
    "        weight.append(len(y)/(n_classes*count))\n",
    "    return classes_count,weight\n",
    "\n",
    "def eval_loop_func(model, loader, labels, device, loss_weight, num_classes):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    losses=[]\n",
    "    for input_nodes_raw, seeds, blocks in tqdm(loader, position=0, leave=True):\n",
    "        blocks = [blk.to(device) for blk in blocks]\n",
    "        seeds = seeds.to(device)\n",
    "        \n",
    "        input_nodes={}\n",
    "        input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "        input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "\n",
    "        lbl = labels[seeds].squeeze().to(device)\n",
    "        \n",
    "        with th.no_grad():\n",
    "            logits,h = model(input_nodes,blocks)\n",
    "            if loss_weight is None:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes), lbl.to(device))\n",
    "            else:\n",
    "                loss = F.cross_entropy(logits.view(-1, num_classes), lbl.to(device),weight=th.Tensor(loss_weight).to(device))        \n",
    "            losses.append(loss.item())\n",
    "        fin_targets.append(lbl.cpu().detach().numpy())\n",
    "        fin_outputs.append(logits.cpu().detach().numpy())\n",
    "    return np.concatenate(fin_outputs), np.concatenate(fin_targets), losses\n",
    "\n",
    "def evaluate(pred_test, y_test):\n",
    "    \n",
    "    ## convert logits into probability\n",
    "    pred_test=th.nn.functional.softmax(th.from_numpy(pred_test),dim=1).numpy()\n",
    "    \n",
    "    acc = np.sum(pred_test.argmax(axis=1) == y_test.squeeze()) / y_test.shape[0]\n",
    "    prec_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='macro')\n",
    "    prec_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='micro')\n",
    "    prec_weighted, recall_weighted, fscore_weighted, _ = precision_recall_fscore_support(y_test.squeeze(), pred_test.argmax(axis=1), average='weighted')\n",
    "    \n",
    "    macro_roc_auc_ovo=roc_auc_score(y_test,pred_test,multi_class=\"ovo\",average=\"macro\")\n",
    "    weighted_roc_auc_ovo=roc_auc_score(y_test,pred_test,multi_class=\"ovo\",average=\"weighted\")\n",
    "\n",
    "    macro_roc_auc_ovr=roc_auc_score(y_test,pred_test,multi_class=\"ovr\",average=\"macro\")\n",
    "    weighted_roc_auc_ovr=roc_auc_score(y_test,pred_test,multi_class=\"ovr\",average=\"weighted\")\n",
    "    \n",
    "    \n",
    "    _, count=np.unique(y_test,return_counts=True)\n",
    "    weight=count/count.sum()\n",
    "    \n",
    "    y_test_binary=label_binarize(y_test, classes=np.unique(y_test).tolist())\n",
    "    \n",
    "    roc_auc = dict()\n",
    "    pr_auc = dict()\n",
    "    n_classes = y_test_binary.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        fpr, tpr, _ = roc_curve(y_test_binary[:, i],pred_test[:, i])\n",
    "        roc_auc[i] = auc_score(fpr, tpr)\n",
    "        \n",
    "        prec,rec,_ = precision_recall_curve(y_test_binary[:, i], th.sigmoid(th.from_numpy(pred_test))[:,i].numpy())\n",
    "        pr_auc[i]=auc_score(rec,prec)\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr, tpr, _ = roc_curve(y_test_binary.ravel(), pred_test.ravel())\n",
    "    roc_auc[\"micro\"] = auc_score(fpr, tpr)\n",
    "    roc_auc[\"macro\"]=0\n",
    "    roc_auc[\"weighted\"]=0\n",
    "    for i in range(n_classes):\n",
    "        roc_auc[\"macro\"]+=roc_auc[i]\n",
    "        roc_auc[\"weighted\"]+=roc_auc[i]*weight[i]\n",
    "    roc_auc[\"macro\"]/=n_classes\n",
    "    \n",
    "    prec,rec,_ = precision_recall_curve(y_test_binary.ravel(), th.sigmoid(th.from_numpy(pred_test)).numpy().ravel())\n",
    "    pr_auc[\"micro\"]=auc_score(rec,prec)\n",
    "\n",
    "    pr_auc[\"macro\"]=0\n",
    "    pr_auc[\"weighted\"]=0\n",
    "    for i in range(n_classes):\n",
    "        pr_auc[\"macro\"]+=pr_auc[i]\n",
    "        pr_auc[\"weighted\"]+=pr_auc[i]*weight[i]\n",
    "    pr_auc[\"macro\"]/=n_classes\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['acc'] = acc\n",
    "    metrics['prec_macro'] = prec_macro\n",
    "    metrics['recall_macro'] = recall_macro\n",
    "    metrics['fscore_macro'] = fscore_macro\n",
    "\n",
    "    metrics['prec_micro'] = prec_micro\n",
    "    metrics['recall_micro'] = recall_micro\n",
    "    metrics['fscore_micro'] = fscore_micro\n",
    "\n",
    "    metrics['prec_weighted'] = prec_weighted\n",
    "    metrics['recall_weighted'] = recall_weighted\n",
    "    metrics['fscore_weighted'] = fscore_weighted\n",
    "    \n",
    "    metrics['auc_micro']=roc_auc[\"micro\"]\n",
    "    \n",
    "    metrics['auc_macro_ovo']=macro_roc_auc_ovo\n",
    "    metrics['auc_macro_ovr']=macro_roc_auc_ovr\n",
    "    \n",
    "    metrics['auc_weighted_ovo']=weighted_roc_auc_ovo\n",
    "    metrics['auc_weighted_ovr']=weighted_roc_auc_ovr  \n",
    "    \n",
    "    metrics['pr_auc_micro']=pr_auc[\"micro\"]\n",
    "    metrics['pr_auc_macro']=pr_auc[\"macro\"]\n",
    "    metrics['pr_auc_weighted']=pr_auc[\"weighted\"]\n",
    "\n",
    "    return metrics, roc_auc, pr_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, loader, labels, category, device):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     total_acc = 0\n",
    "# #     total_precision=0\n",
    "# #     total_recall=0\n",
    "#     total_fscore_macro=0\n",
    "#     total_fscore_micro=0\n",
    "#     total_fscore_weighted=0\n",
    "# #     total_auc=0\n",
    "# #     total_pr_auc=0\n",
    "    \n",
    "#     count = 0\n",
    "#     count_loss=0\n",
    "    \n",
    "#     y_pred=[]\n",
    "#     y_true=[]\n",
    "    \n",
    "#     for input_nodes_raw, seeds_raw, blocks in tqdm(loader, position=0, leave=True):\n",
    "#         blocks = [blk.to(device) for blk in blocks]\n",
    "        \n",
    "#         seeds=seeds_raw.to(device)\n",
    "        \n",
    "#         input_nodes={}\n",
    "#         input_nodes[category]=input_nodes_raw\n",
    "#         input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "        \n",
    "#         lbl = labels[seeds].to(device)\n",
    "#         logits,h = model(input_nodes,blocks)\n",
    "#         loss = F.cross_entropy(logits, lbl.squeeze(1).to(device))\n",
    "# #         loss = F.cross_entropy(logits, lbl.squeeze(1),weight=th.Tensor([1,args.weight]).to(device))\n",
    "#         acc = th.sum(logits.argmax(dim=1) == lbl.squeeze(1)).item() / logits.shape[0]\n",
    "# #         precision, recall, fscore, support = score(lbl.squeeze(1).cpu().numpy(), logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "#         precision_macro, recall_macro, fscore_macro, _ = score(lbl.squeeze().cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='macro')\n",
    "#         precision_micro, recall_micro, fscore_micro, _ = score(lbl.squeeze().cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='micro')\n",
    "#         precision_weighted, recall_weighted, fscore_weighted, _ = score(lbl.squeeze().cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='weighted')\n",
    "        \n",
    "#         y_pred.extend(logits.argmax(dim=1).tolist())\n",
    "#         y_true.extend(lbl.squeeze().tolist())\n",
    "        \n",
    "# #         tempt=lbl.detach().cpu().numpy()\n",
    "# #         labels_train_one_hot=np.zeros(shape=(tempt.shape[0],8),dtype=np.float32)\n",
    "# #         labels_train_one_hot[np.arange(tempt.shape[0]),np.array([ele.item() for ele in tempt])]=1\n",
    "# #         auc = roc_auc_score(labels_train_one_hot.ravel(), th.sigmoid(logits).detach().cpu().numpy().ravel())\n",
    "        \n",
    "# #         auc = roc_auc_score(lbl.detach().cpu().numpy().ravel(), th.sigmoid(logits)[:,1].detach().cpu().numpy().ravel())\n",
    "# #         prec,rec,_ = precision_recall_curve(lbl.detach().cpu().numpy().ravel(), th.sigmoid(logits)[:,1].detach().cpu().numpy().ravel())\n",
    "# #         pr_auc=auc_score(rec,prec)\n",
    "        \n",
    "#         total_loss += loss.item() * len(seeds) \n",
    "#         total_acc += acc\n",
    "# #         total_precision += precision[1]\n",
    "# #         total_recall += recall[1]\n",
    "#         total_fscore_macro += fscore_macro\n",
    "#         total_fscore_micro += fscore_micro\n",
    "#         total_fscore_weighted += fscore_weighted\n",
    "# #         total_auc += auc\n",
    "# #         total_pr_auc += pr_auc\n",
    "#         count += 1\n",
    "#         count_loss += len(seeds)\n",
    "    \n",
    "#     ACCURACY=total_acc / count\n",
    "#     LOSS=total_loss / count_loss\n",
    "# #     PRECISION=total_precision/count\n",
    "# #     RECALL=total_recall/count\n",
    "#     F1_SCORE_macro=total_fscore_macro/count\n",
    "#     F1_SCORE_micro=total_fscore_micro/count\n",
    "#     F1_SCORE_weighted=total_fscore_weighted/count\n",
    "# #     AUC=total_auc/count\n",
    "# #     PR_AUC=total_pr_auc/count\n",
    "    \n",
    "#     return ACCURACY, LOSS, F1_SCORE_macro, F1_SCORE_micro, F1_SCORE_weighted, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, graph, input_features, batch_size):\n",
    "    \"\"\"Minibatch inference of final representation over all node types.\n",
    "    ***NOTE***\n",
    "    For node classification, the model is trained to predict on only one node type's\n",
    "    label.  Therefore, only that type's final representation is meaningful.\n",
    "    \"\"\"\n",
    "    with th.no_grad():\n",
    "        for l, layer in enumerate(model.layers):\n",
    "            \n",
    "            output_features = {\n",
    "                k: th.zeros(\n",
    "                    graph.number_of_nodes(k),\n",
    "                    args.h_dim )\n",
    "                for k in graph.ntypes}\n",
    "            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)\n",
    "            dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                graph,\n",
    "                {k: th.arange(graph.number_of_nodes(k)) for k in graph.ntypes},\n",
    "                sampler,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=False,\n",
    "                num_workers=0)\n",
    "            \n",
    "#             dataloader=[next(iter(dataloader)) for idx in range(10)]\n",
    "            for input_nodes, output_nodes, blocks in tqdm(dataloader, position=0, leave=True):\n",
    "                block = blocks[0].to(device)\n",
    "                h = {k: input_features[k][input_nodes[k]].to(device) for k in input_nodes.keys()}\n",
    "                h = layer(block, h)\n",
    "                for k in h.keys():\n",
    "#                     h[k]=th.matmul(h[k],model.classifier.weight.t())+model.classifier.bias\n",
    "                    output_features[k][output_nodes[k]] = h[k].cpu()\n",
    "            input_features = output_features\n",
    "        \n",
    "    return model.classifier(output_features[\"usaanr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_edges={}\n",
    "# for etype in G.etypes:\n",
    "#     dict_edges[etype]=th.arange(G.num_edges(etype))[0:5000]\n",
    "# G=dgl.edge_subgraph(G,dict_edges)\n",
    "\n",
    "# G.nodes['usaanr'].data[\"_ID\"].numpy().shape,node_labels.shape, node_labels[G.nodes['usaanr'].data[\"_ID\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='RGCN')\n",
    "parser.add_argument(\"--dropout\", type=float, default=0,\n",
    "        help=\"dropout probability\")\n",
    "parser.add_argument(\"--h_dim\", type=int, default=128,\n",
    "        help=\"number of hidden units\")\n",
    "parser.add_argument(\"--out_dim\", type=int, default=1,\n",
    "        help=\"output dimension\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "        help=\"gpu\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-5,\n",
    "        help=\"learning rate\")\n",
    "parser.add_argument(\"--num_bases\", type=int, default=-1,\n",
    "        help=\"number of filter weight matrices, default: -1 [use all]\")\n",
    "parser.add_argument(\"--num_layers\", type=int, default=1,\n",
    "        help=\"number of propagation rounds\")\n",
    "parser.add_argument(\"-e\", \"--n_epochs\", type=int, default=1,\n",
    "        help=\"number of training epochs\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"/workspace/cjiang/eagle_project/CAP_graph/CAP_without_zipcode/rgcn_model_param.pt\",\n",
    "        help='path for save the model')\n",
    "parser.add_argument(\"--l2norm\", type=float, default=0,\n",
    "        help=\"l2 norm coef\")\n",
    "parser.add_argument(\"--use_self_loop\", default=True, action='store_true',\n",
    "        help=\"include self feature as a special relation\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=1024,\n",
    "        help=\"Mini-batch size. If -1, use full graph training.\")\n",
    "parser.add_argument(\"--num_mini_batch\", type=int, default=8,\n",
    "        help=\"Number of minibatch.\")\n",
    "parser.add_argument(\"--fanout\", type=int, default=None,\n",
    "        help=\"Fan-out of neighbor sampling.\")\n",
    "parser.add_argument(\"--validation\",  default=True,\n",
    "        help=\"set up validation .\")\n",
    "parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "        help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "\n",
    "parser.add_argument(\"--loss_weight\",  type=bool,default=True,  ## number of label=0/number of label=1\n",
    "        help=\"weight for unbalance data\")\n",
    "parser.add_argument(\"--num_worker\",  type=int,default=0,  \n",
    "        help=\"number of worker for neighbor sampling\") \n",
    "    \n",
    "args,unknown=parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=10240, dropout=0.2, fanout=None, gpu=0, h_dim=64, l2norm=0.001, loss_weight=True, lr=0.001, model_path='/workspace/cjiang/eagle_project/CAP_graph/CAP_without_zipcode/rgcn_model_param.pt', n_epochs=1, num_bases=5, num_layers=1, num_mini_batch=8, num_worker=0, out_dim=1, seed=101, use_self_loop=True, validation=True)\n"
     ]
    }
   ],
   "source": [
    "args.num_layers=1\n",
    "args.dropout=0.2\n",
    "args.lr=1e-3\n",
    "args.l2norm=1e-3\n",
    "args.n_epochs=1\n",
    "args.num_bases=5\n",
    "args.h_dim=64\n",
    "args.batch_size=1024*10\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >category</th>        <th class=\"col_heading level0 col1\" >product_type</th>        <th class=\"col_heading level0 col2\" >count</th>        <th class=\"col_heading level0 col3\" >percentage</th>        <th class=\"col_heading level0 col4\" >weight</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row0_col1\" class=\"data row0 col1\" >No Product</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row0_col2\" class=\"data row0 col2\" >18,891,343</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row0_col3\" class=\"data row0 col3\" >73.60%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row0_col4\" class=\"data row0 col4\" >0.23</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row1_col1\" class=\"data row1 col1\" >Rental Only</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row1_col2\" class=\"data row1 col2\" >239,092</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row1_col3\" class=\"data row1 col3\" >0.93%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row1_col4\" class=\"data row1 col4\" >17.89</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row2_col1\" class=\"data row2 col1\" >Home Only</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row2_col2\" class=\"data row2 col2\" >228,478</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row2_col3\" class=\"data row2 col3\" >0.89%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row2_col4\" class=\"data row2 col4\" >18.72</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row3_col1\" class=\"data row3 col1\" >Auto Only</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row3_col2\" class=\"data row3 col2\" >2,123,839</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row3_col3\" class=\"data row3 col3\" >8.27%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row3_col4\" class=\"data row3 col4\" >2.01</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row4_col1\" class=\"data row4 col1\" >Auto + Rental</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row4_col2\" class=\"data row4 col2\" >1,238,210</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row4_col3\" class=\"data row4 col3\" >4.82%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row4_col4\" class=\"data row4 col4\" >3.46</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row5_col1\" class=\"data row5 col1\" >Auto + Home</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row5_col2\" class=\"data row5 col2\" >2,947,542</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row5_col3\" class=\"data row5 col3\" >11.48%</td>\n",
       "                        <td id=\"T_6da063b4_e0b6_11eb_9b01_7922bef9b8e8row5_col4\" class=\"data row5 col4\" >1.45</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2e81f860f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=multi_label.squeeze().numpy()\n",
    "n_classes=th.unique(multi_label).shape[0]\n",
    "classes_count,weight=get_class_count_weight(y,n_classes)\n",
    "imbalance_classes={}\n",
    "imbalance_classes[\"category\"]=th.unique(multi_label).tolist()\n",
    "imbalance_classes[\"product_type\"]=[\"No Product\",\"Rental Only\",\"Home Only\",\"Auto Only\",\"Auto + Rental\",\"Auto + Home\"]\n",
    "imbalance_classes[\"count\"]=classes_count\n",
    "imbalance_classes[\"percentage\"]=classes_count/sum(classes_count)\n",
    "imbalance_classes[\"weight\"]=weight\n",
    "imbalance_classes=pd.DataFrame(imbalance_classes)\n",
    "imbalance_classes.style.format({\"count\":\"{:,}\",\"percentage\":\"{:.2%}\",\"weight\":\"{:.2f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2e81f86588>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(multi_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting up training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set    20,534,806\n",
      "validation set  2,566,850 \n",
      "test set        2,566,848 \n"
     ]
    }
   ],
   "source": [
    "train_idx=th.nonzero(train_mask_multi_label.squeeze()).numpy()\n",
    "val_idx=th.nonzero(val_mask_multi_label.squeeze()).numpy()\n",
    "test_idx=th.nonzero(test_mask_multi_label.squeeze()).numpy()\n",
    "\n",
    "train_idx=th.from_numpy(train_idx).squeeze()    \n",
    "val_idx=th.from_numpy(val_idx).squeeze()    \n",
    "test_idx=th.from_numpy(test_idx).squeeze()\n",
    "\n",
    "train_label=binary_label[train_idx].squeeze().numpy()\n",
    "val_label=binary_label[val_idx].squeeze().numpy()\n",
    "test_label=binary_label[test_idx].squeeze().numpy()\n",
    "\n",
    "print('{:<15} {:<10,}'.format(\"Training set\",train_idx.shape[0]))\n",
    "print('{:<15} {:<10,}'.format(\"validation set\",val_idx.shape[0]))\n",
    "print('{:<15} {:<10,}'.format(\"test set\",test_idx.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "##### check cuda\n",
    "device=\"cpu\"\n",
    "use_cuda=args.gpu>=0 and th.cuda.is_available()\n",
    "if use_cuda:\n",
    "    th.cuda.set_device(args.gpu)\n",
    "    device='cuda:%d' % args.gpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=th.unique(th.from_numpy(train_label)).shape[0]\n",
    "if args.loss_weight:\n",
    "    train_classes_num, train_classes_weight = get_class_count_weight(train_label,num_classes)\n",
    "    loss_weight=th.tensor(train_classes_weight).to(device)\n",
    "else:\n",
    "    loss_weight=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): RelGraphConvLayer(\n",
       "    (conv): HeteroGraphConv(\n",
       "      (mods): ModuleDict(\n",
       "        (AUTO_RELATED): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Brother_Sister): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Busi_rel_Other): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Child): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Ex-Spouse): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Parent): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Pers_rel_Other): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (SPONSEE): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (SPONSOR): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Spouse): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Step-Child): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "        (Step-Parent): GraphConv(in=64, out=64, normalization=both, activation=None)\n",
       "      )\n",
       "    )\n",
       "    (basis): WeightBasis()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Entity_Classify(G,\n",
    "                       feat_list,\n",
    "                       args.h_dim,\n",
    "                       n_classes,\n",
    "                       num_bases=args.num_bases,\n",
    "                       num_hidden_layers=args.num_layers,\n",
    "                       dropout=args.dropout,\n",
    "                       use_self_loop=args.use_self_loop)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of minibatch in training set is 2,006\n",
      "The number of minibatch in validation set is 251\n",
      "The number of minibatch in test set is 251\n"
     ]
    }
   ],
   "source": [
    "# train sampler\n",
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([args.fanout] * args.num_layers)\n",
    "train_loader = dgl.dataloading.NodeDataLoader(\n",
    "    G, {'usaanr': train_idx}, sampler,\n",
    "    batch_size=args.batch_size, shuffle=True, num_workers=args.num_worker)\n",
    "# validation sampler\n",
    "# we do not use full neighbor to save computation resources\n",
    "val_sampler = dgl.dataloading.MultiLayerNeighborSampler([args.fanout] * args.num_layers)\n",
    "val_loader = dgl.dataloading.NodeDataLoader(\n",
    "    G, {'usaanr': val_idx}, val_sampler,\n",
    "    batch_size=args.batch_size, shuffle=False, num_workers=args.num_worker)\n",
    "\n",
    "test_sampler = dgl.dataloading.MultiLayerNeighborSampler([args.fanout] * args.num_layers)\n",
    "test_loader = dgl.dataloading.NodeDataLoader(\n",
    "    G, {'usaanr': test_idx}, test_sampler,\n",
    "    batch_size=args.batch_size, shuffle=False, num_workers=args.num_worker)\n",
    "\n",
    "print(\"The number of minibatch in training set is {:,}\".format(len(train_loader)))\n",
    "print(\"The number of minibatch in validation set is {:,}\".format(len(val_loader)))\n",
    "print(\"The number of minibatch in test set is {:,}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total # of parameter is 43,010\n"
     ]
    }
   ],
   "source": [
    "print(\"The total # of parameter is {:,}\".format(sum([p.nelement() for p in model.parameters()]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_embed.usaanr.emb.usaayr.weight                                   5,440          \n",
      "node_embed.usaanr.emb.AGE_BAND.weight                                 448            \n",
      "node_embed.usaanr.emb.ORIGEL.weight                                   2,752          \n",
      "node_embed.usaanr.emb.ELIG2.weight                                    384            \n",
      "node_embed.usaanr.emb.cmpyelig.weight                                 320            \n",
      "node_embed.usaanr.emb.SEX.weight                                      320            \n",
      "node_embed.usaanr.emb.MARST.weight                                    640            \n",
      "node_embed.usaanr.emb.BRANCH.weight                                   1,088          \n",
      "node_embed.usaanr.emb.MILST.weight                                    512            \n",
      "node_embed.usaanr.emb.MLIST_OrigStat.weight                           192            \n",
      "node_embed.usaanr.emb.ENLPAYGD.weight                                 1,600          \n",
      "node_embed.usaanr.emb.ACTCORP.weight                                  128            \n",
      "node_embed.usaanr.emb.STATE.weight                                    3,712          \n",
      "node_embed.usaanr.emb.Segment.weight                                  384            \n",
      "layers.0.h_bias                                                       64             \n",
      "layers.0.loop_weight                                                  4,096          \n",
      "layers.0.basis.weight                                                 20,480         \n",
      "layers.0.basis.w_comp                                                 60             \n",
      "classifier.weight                                                     384            \n",
      "classifier.bias                                                       6              \n"
     ]
    }
   ],
   "source": [
    "param_dict={n: p.nelement() for n, p in model.named_parameters()}\n",
    "for i,j in param_dict.items():\n",
    "    print(\"{:<70}{:<15,}\".format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "\n",
      "========= Epoch 1 /1\n",
      "Training...\n",
      "Batch 200 of 2006 | Loss 0.815  | Accuracy 85.59% | F1-Score(macro) 50.23%  | F1-Score(micro) 85.59% | F1-Score(weighted) 86.95% | Elapsed: 0:01:11\n",
      "Batch 400 of 2006 | Loss 0.720  | Accuracy 86.49% | F1-Score(macro) 52.53%  | F1-Score(micro) 86.49% | F1-Score(weighted) 87.69% | Elapsed: 0:02:03\n",
      "Batch 600 of 2006 | Loss 0.686  | Accuracy 87.79% | F1-Score(macro) 55.57%  | F1-Score(micro) 87.79% | F1-Score(weighted) 88.83% | Elapsed: 0:02:53\n",
      "Batch 800 of 2006 | Loss 0.667  | Accuracy 87.70% | F1-Score(macro) 56.12%  | F1-Score(micro) 87.70% | F1-Score(weighted) 88.95% | Elapsed: 0:03:51\n",
      "Batch 1000 of 2006 | Loss 0.659  | Accuracy 87.76% | F1-Score(macro) 56.46%  | F1-Score(micro) 87.76% | F1-Score(weighted) 88.78% | Elapsed: 0:04:40\n",
      "Batch 1200 of 2006 | Loss 0.656  | Accuracy 87.82% | F1-Score(macro) 57.62%  | F1-Score(micro) 87.82% | F1-Score(weighted) 88.82% | Elapsed: 0:05:34\n",
      "Batch 1400 of 2006 | Loss 0.645  | Accuracy 87.67% | F1-Score(macro) 54.65%  | F1-Score(micro) 87.67% | F1-Score(weighted) 88.58% | Elapsed: 0:06:31\n",
      "Batch 1600 of 2006 | Loss 0.644  | Accuracy 87.95% | F1-Score(macro) 55.80%  | F1-Score(micro) 87.95% | F1-Score(weighted) 89.02% | Elapsed: 0:07:35\n",
      "Batch 1800 of 2006 | Loss 0.644  | Accuracy 87.75% | F1-Score(macro) 55.79%  | F1-Score(micro) 87.75% | F1-Score(weighted) 89.00% | Elapsed: 0:08:24\n",
      "Batch 2000 of 2006 | Loss 0.648  | Accuracy 87.53% | F1-Score(macro) 54.21%  | F1-Score(micro) 87.53% | F1-Score(weighted) 88.73% | Elapsed: 0:09:16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2006 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running Validation on training set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2006/2006 [06:12<00:00,  5.38it/s]\n",
      "  1%|          | 2/251 [00:00<00:22, 11.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.626 |  Accuracy 88.23% | F1-Score(macro) 56.84%  | F1-Score(weighted) 89.30%  | roc-auc(macro) 94.06%  | roc-auc(weighted) 97.78%  | pr-auc(macro) 64.91%  | pr-auc(weighted) 93.03%  | Elapsed: 0:13:14\n",
      "\n",
      "\n",
      "Running Validation on validation set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 251/251 [00:48<00:00,  5.17it/s]\n",
      "100%|| 1/1 [23:55<00:00, 1435.17s/it]\n",
      "  1%|          | 2/251 [00:00<00:21, 11.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.609 |  Accuracy 88.21% | F1-Score(macro) 56.79%  | F1-Score(weighted) 89.28%  | roc-auc(macro) 94.03%  | roc-auc(weighted) 97.77%  | pr-auc(macro) 64.84%  | pr-auc(weighted) 93.02%  | Elapsed: 0:01:25\n",
      "\n",
      "\n",
      "Running Validation in Test Dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 251/251 [00:49<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.608 |  Accuracy 88.22% | F1-Score(macro) 56.80%  | F1-Score(weighted) 89.29%  | roc-auc(macro) 94.05%  | roc-auc(weighted) 97.78%  | pr-auc(macro) 64.74%  | pr-auc(weighted) 93.01%  | Elapsed: 0:01:26\n"
     ]
    }
   ],
   "source": [
    "# %pdb\n",
    "LOSS_EPOCH=[]\n",
    "LABEL_TRAIN=[]\n",
    "\n",
    "# training loop\n",
    "print(\"start training...\")\n",
    "\n",
    "total_loss=0\n",
    "losses=[]\n",
    "\n",
    "train_true=[]\n",
    "train_pred=[]\n",
    "\n",
    "# th.manual_seed(args.seed)\n",
    "# th.cuda.manual_seed(args.seed)\n",
    "# th.cuda.manual_seed_all(args.seed)\n",
    "# np.ranom.seed(args.seed)\n",
    "# random.seed(args.seed)\n",
    "# th.backends.cudnn.deterministic=True\n",
    "\n",
    "for epoch in tqdm(range(0,args.n_epochs)):\n",
    "    \n",
    "    model.train()\n",
    "    IDX=[]\n",
    "    H=[]\n",
    "    \n",
    "    #====================================#\n",
    "    #            Traning                 #\n",
    "    #====================================#\n",
    "    print(\"\")\n",
    "    print(\"========= Epoch {:} /{:}\".format(epoch+1,args.n_epochs))\n",
    "    print(\"Training...\")\n",
    "    t0 = time.time()\n",
    "    for step, (input_nodes_raw, seeds_raw, blocks) in enumerate(train_loader):\n",
    "        blocks = [blk.to(device) for blk in blocks]\n",
    "        \n",
    "        seeds=seeds_raw.to(device)\n",
    "        \n",
    "        labels_train=multi_label[seeds]       \n",
    "        labels_train = labels_train.to(device)\n",
    "        \n",
    "        input_nodes={}\n",
    "        input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "        input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "        \n",
    "        logits,h = model(input_nodes,blocks)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.cross_entropy(logits, labels_train.squeeze(1),weight=th.Tensor(weight).to(device))\n",
    "#         loss = F.cross_entropy(logits, labels_train.squeeze(1).to(device))\n",
    "        total_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        train_pred.extend(logits.argmax(dim=1).tolist())\n",
    "        train_true.extend(labels_train.squeeze(1).tolist())\n",
    "\n",
    "        train_acc = th.sum(logits.argmax(dim=1) == labels_train.squeeze(1)).item() / len(seeds)\n",
    "        precision_macro, recall_macro, fscore_macro, _ = precision_recall_fscore_support(labels_train.squeeze(1).cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='macro')\n",
    "        precision_micro, recall_micro, fscore_micro, _ = precision_recall_fscore_support(labels_train.squeeze(1).cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='micro')\n",
    "        precision_weighted, recall_weighted, fscore_weighted, _ = precision_recall_fscore_support(labels_train.squeeze(1).cpu().numpy(), logits.argmax(dim=1).cpu().numpy(), average='weighted')\n",
    "\n",
    "#         macro_roc_auc_ovo=roc_auc_score(labels_train,logits,multi_class=\"ovo\",average=\"macro\")\n",
    "#         weighted_roc_auc_ovo=roc_auc_score(labels_train,logits,multi_class=\"ovo\",average=\"weighted\")\n",
    "        \n",
    "        \n",
    "#         _, count=np.unique(labels_train,return_counts=True)\n",
    "#         W=count/count.sum()\n",
    "\n",
    "#         labels_train_binary=label_binarize(labels_train, classes=np.unique(labels_train).tolist())\n",
    "\n",
    "#         roc_auc = dict()\n",
    "#         pr_auc = dict()\n",
    "#         n_classes = labels_train_binary.shape[1]\n",
    "#         for i in range(n_classes):\n",
    "#             fpr, tpr, _ = roc_curve(labels_train_binary[:, i],preds[:, i])\n",
    "#             roc_auc[i] = auc_score(fpr, tpr)\n",
    "\n",
    "#             prec,rec,_ = precision_recall_curve(labels_train_binary[:, i], th.sigmoid(th.from_numpy(logits))[:,i].numpy())\n",
    "#             pr_auc[i]=auc_score(rec,prec)\n",
    "\n",
    "#         # Compute micro-average ROC curve and ROC area\n",
    "#         fpr, tpr, _ = roc_curve(labels_train_binary.ravel(), logits.ravel())\n",
    "#         roc_auc[\"micro\"] = auc_score(fpr, tpr)\n",
    "#         roc_auc[\"macro\"]=0\n",
    "#         roc_auc[\"weighted\"]=0\n",
    "#         for i in range(n_classes):\n",
    "#             roc_auc[\"macro\"]+=roc_auc[i]\n",
    "#             roc_auc[\"weighted\"]+=roc_auc[i]*weight[i]\n",
    "#         roc_auc[\"macro\"]/=n_classes\n",
    "\n",
    "#         prec,rec,_ = precision_recall_curve(labels_train_binary.ravel(), torch.sigmoid(torch.from_numpy(logits)).numpy().ravel())\n",
    "#         pr_auc[\"micro\"]=auc_score(rec,prec)\n",
    "\n",
    "#         pr_auc[\"macro\"]=0\n",
    "#         pr_auc[\"weighted\"]=0\n",
    "#         for i in range(n_classes):\n",
    "#             pr_auc[\"macro\"]+=pr_auc[i]\n",
    "#             pr_auc[\"weighted\"]+=pr_auc[i]*weight[i]\n",
    "#         pr_auc[\"macro\"]/=n_classes\n",
    "\n",
    "\n",
    "        IDX.extend(seeds.detach().cpu().numpy().tolist())\n",
    "        H.extend(h.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        if step%(len(train_loader)//10)==0 and not step==0:\n",
    "\n",
    "            t1 = time.time()\n",
    "            elapsed=utils.format_time(t1-t0)\n",
    "            print(\"Batch {:} of {:} | Loss {:.3f}  | Accuracy {:.2%} | F1-Score(macro) {:.2%}  | F1-Score(micro) {:.2%} | F1-Score(weighted) {:.2%} | Elapsed: {:}\".\\\n",
    "                  format(step,len(train_loader),np.mean(losses[-10:]),train_acc,fscore_macro,fscore_micro,fscore_weighted,elapsed))    \n",
    "    \n",
    "    LOSS_EPOCH.append(loss)\n",
    "\n",
    "    LABEL_TRAIN.append(multi_label[blocks[-1].nodes[\"usaanr\"].data[dgl.NID].cpu().numpy()])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    print()\n",
    "    print(\"\")\n",
    "    print(\"Running Validation on training set\")\n",
    "    print(\"\")\n",
    "    fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, train_loader, multi_label,  device, weight, n_classes)\n",
    "    \n",
    "    avg_loss_train=np.mean(losses_tmp)\n",
    "    \n",
    "    metrics_train, roc_auc_train, pr_auc_train = evaluate(fin_outputs, fin_targets)\n",
    "    \n",
    "    t2=time.time()\n",
    "    \n",
    "    print(\"loss: {:.3f} |  Accuracy {:.2%} | F1-Score(macro) {:.2%}  | F1-Score(weighted) {:.2%}  | roc-auc(macro) {:.2%}  | roc-auc(weighted) {:.2%}  | pr-auc(macro) {:.2%}  | pr-auc(weighted) {:.2%}  | Elapsed: {:}\"\\\n",
    "      .format(avg_loss_train, metrics_train[\"acc\"],  metrics_train['fscore_macro'], metrics_train['fscore_weighted'],  \\\n",
    "              metrics_train['auc_macro_ovo'], metrics_train['auc_weighted_ovo'],metrics_train['pr_auc_macro'], \\\n",
    "              metrics_train['pr_auc_weighted'],utils.format_time(t2-t1)))\n",
    "\n",
    "    #====================================#\n",
    "    #            Validation-set          #\n",
    "    #====================================#\n",
    "    \n",
    "    model.eval()\n",
    "    print()\n",
    "    print(\"\")\n",
    "    print(\"Running Validation on validation set\")\n",
    "    print(\"\")\n",
    "    \n",
    "    fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, val_loader, multi_label, device, weight, n_classes)\n",
    "    \n",
    "    avg_loss_val=np.mean(losses_tmp)\n",
    "    \n",
    "    metrics_val, roc_auc_val, pr_auc_val = evaluate(fin_outputs, fin_targets)\n",
    "    \n",
    "    t3=time.time()\n",
    "    \n",
    "    print(\"loss: {:.3f} |  Accuracy {:.2%} | F1-Score(macro) {:.2%}  | F1-Score(weighted) {:.2%}  | roc-auc(macro) {:.2%}  | roc-auc(weighted) {:.2%}  | pr-auc(macro) {:.2%}  | pr-auc(weighted) {:.2%}  | Elapsed: {:}\"\\\n",
    "          .format(avg_loss_val, metrics_val[\"acc\"],  metrics_val['fscore_macro'], metrics_val['fscore_weighted'],  \\\n",
    "          metrics_val['auc_macro_ovo'], metrics_val['auc_weighted_ovo'],metrics_val['pr_auc_macro'], \\\n",
    "          metrics_val['pr_auc_weighted'],utils.format_time(t3-t2)))\n",
    "    \n",
    "# if args.model_path is not None:\n",
    "#     th.save(model.state_dict(), args.model_path)\n",
    "    \n",
    "#====================================#\n",
    "#            Test-set                #\n",
    "#====================================#\n",
    "print()\n",
    "print(\"\")\n",
    "print(\"Running Validation in Test Dataset\")\n",
    "print(\"\")\n",
    "model.eval()\n",
    "\n",
    "fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, test_loader, multi_label,  device, weight, n_classes)\n",
    "    \n",
    "avg_loss_test=np.mean(losses_tmp)\n",
    "\n",
    "metrics_test, roc_auc_test, pr_auc_test = evaluate(fin_outputs, fin_targets)\n",
    "\n",
    "t4=time.time()\n",
    "\n",
    "print(\"loss: {:.3f} |  Accuracy {:.2%} | F1-Score(macro) {:.2%}  | F1-Score(weighted) {:.2%}  | roc-auc(macro) {:.2%}  | roc-auc(weighted) {:.2%}  | pr-auc(macro) {:.2%}  | pr-auc(weighted) {:.2%}  | Elapsed: {:}\"\\\n",
    "  .format(avg_loss_test, metrics_test[\"acc\"],  metrics_test['fscore_macro'], metrics_test['fscore_weighted'],  \\\n",
    "          metrics_test['auc_macro_ovo'], metrics_test['auc_weighted_ovo'],metrics_test['pr_auc_macro'], \\\n",
    "          metrics_test['pr_auc_weighted'],utils.format_time(t4-t3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2006 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********  model performance in training set **********  \n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2006/2006 [06:22<00:00,  5.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy            88.23%    \n",
      "\n",
      "precision(macro):   58.25%    recall(macro):  72.39%    f1-score(macro):  56.84%    ROC-AUC(macro):  94.06%    PR-AUC(macro):  64.91%    \n",
      "precision(micro):   88.23%    recall(micro):  88.23%    f1-score(micro):  88.23%    ROC-AUC(micro):  99.33%    PR-AUC(micro):  97.11%    \n",
      "precision(weight):  92.09%    recall(weight): 88.23%    f1-score(weight): 89.30%    ROC-AUC(weight): 97.78%    PR-AUC(weight): 93.03%    \n",
      "\n",
      "CPU times: user 12min 21s, sys: 1min 52s, total: 14min 13s\n",
      "Wall time: 13min 58s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >product_type</th>        <th class=\"col_heading level0 col1\" >count</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1-score</th>        <th class=\"col_heading level0 col5\" >roc_auc</th>        <th class=\"col_heading level0 col6\" >pr_auc</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col0\" class=\"data row0 col0\" >No Product</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col1\" class=\"data row0 col1\" >15,113,075</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col2\" class=\"data row0 col2\" >100.00%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col3\" class=\"data row0 col3\" >99.77%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col4\" class=\"data row0 col4\" >99.89%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col5\" class=\"data row0 col5\" >99.95%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row0_col6\" class=\"data row0 col6\" >99.99%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col0\" class=\"data row1 col0\" >Rental Only</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col1\" class=\"data row1 col1\" >191,274</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col2\" class=\"data row1 col2\" >23.38%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col3\" class=\"data row1 col3\" >98.00%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col4\" class=\"data row1 col4\" >37.76%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col5\" class=\"data row1 col5\" >99.04%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row1_col6\" class=\"data row1 col6\" >43.81%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col0\" class=\"data row2 col0\" >Home Only</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col1\" class=\"data row2 col1\" >182,783</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col2\" class=\"data row2 col2\" >15.29%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col3\" class=\"data row2 col3\" >82.25%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col4\" class=\"data row2 col4\" >25.78%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col5\" class=\"data row2 col5\" >97.90%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row2_col6\" class=\"data row2 col6\" >29.26%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col0\" class=\"data row3 col0\" >Auto Only</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col1\" class=\"data row3 col1\" >1,699,072</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col2\" class=\"data row3 col2\" >71.73%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col3\" class=\"data row3 col3\" >44.49%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col4\" class=\"data row3 col4\" >54.92%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col5\" class=\"data row3 col5\" >97.11%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row3_col6\" class=\"data row3 col6\" >72.59%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col0\" class=\"data row4 col0\" >Auto + Rental</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col1\" class=\"data row4 col1\" >990,568</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col2\" class=\"data row4 col2\" >56.57%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col3\" class=\"data row4 col3\" >47.13%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col4\" class=\"data row4 col4\" >51.42%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col5\" class=\"data row4 col5\" >96.16%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row4_col6\" class=\"data row4 col6\" >56.19%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col0\" class=\"data row5 col0\" >Auto + Home</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col1\" class=\"data row5 col1\" >2,358,034</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col2\" class=\"data row5 col2\" >82.50%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col3\" class=\"data row5 col3\" >62.69%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col4\" class=\"data row5 col4\" >71.25%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col5\" class=\"data row5 col5\" >98.68%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row5_col6\" class=\"data row5 col6\" >87.62%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col0\" class=\"data row6 col0\" >MACRO</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col1\" class=\"data row6 col1\" >20,534,806</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col2\" class=\"data row6 col2\" >58.25%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col3\" class=\"data row6 col3\" >72.39%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col4\" class=\"data row6 col4\" >56.84%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col5\" class=\"data row6 col5\" >94.06%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row6_col6\" class=\"data row6 col6\" >64.91%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col0\" class=\"data row7 col0\" >MICRO</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col1\" class=\"data row7 col1\" >20,534,806</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col2\" class=\"data row7 col2\" >88.23%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col3\" class=\"data row7 col3\" >88.23%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col4\" class=\"data row7 col4\" >88.23%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col5\" class=\"data row7 col5\" >99.33%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row7_col6\" class=\"data row7 col6\" >97.11%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col0\" class=\"data row8 col0\" >WEIGHT</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col1\" class=\"data row8 col1\" >20,534,806</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col2\" class=\"data row8 col2\" >92.09%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col3\" class=\"data row8 col3\" >88.23%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col4\" class=\"data row8 col4\" >89.30%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col5\" class=\"data row8 col5\" >97.78%</td>\n",
       "                        <td id=\"T_f07f390e_e0bb_11eb_9b01_7922bef9b8e8row8_col6\" class=\"data row8 col6\" >93.03%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2a6ff47978>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print()\n",
    "print(\"********  model performance in training set **********  \\n \")\n",
    "print()\n",
    "    \n",
    "fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, train_loader, multi_label, device, weight, n_classes)\n",
    "metrics_dict, roc_auc, pr_auc = evaluate(fin_outputs, fin_targets)\n",
    "\n",
    "print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "print()\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "              \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "             \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "              \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "             \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "              \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "             \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))\n",
    "\n",
    "print()\n",
    "n_classes=th.unique(multi_label).shape[0]\n",
    "label_map={0:\"No Product\",1:\"Rental Only\",2:\"Home Only\",3:\"Auto Only\",4:\"Auto + Rental\",5:\"Auto + Home\"}\n",
    "\n",
    "report=metrics.classification_report(fin_targets.squeeze(), fin_outputs.argmax(axis=1), output_dict=True)\n",
    "\n",
    "table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "table[\"count\"]=table[\"support\"].astype(int)\n",
    "table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "table[\"product_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "table=table[['product_type','count','precision','recall','f1-score','roc_auc','pr_auc']]\n",
    "\n",
    "total=table['count'].sum()\n",
    "\n",
    "table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],\\\n",
    "                        metrics_dict['auc_macro_ovo'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],\\\n",
    "                            metrics_dict['auc_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],\\\n",
    "                        metrics_dict['auc_weighted_ovo'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "table.style.format({\"count\":\"{:,}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"roc_auc\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/251 [00:00<00:22, 10.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********  model performance in validation set **********  \n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 251/251 [00:49<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy            88.21%    \n",
      "\n",
      "precision(macro):   58.20%    recall(macro):  72.31%    f1-score(macro):  56.79%    ROC-AUC(macro):  94.03%    PR-AUC(macro):  64.84%    \n",
      "precision(micro):   88.21%    recall(micro):  88.21%    f1-score(micro):  88.21%    ROC-AUC(micro):  99.33%    PR-AUC(micro):  97.10%    \n",
      "precision(weight):  92.07%    recall(weight): 88.21%    f1-score(weight): 89.28%    ROC-AUC(weight): 97.77%    PR-AUC(weight): 93.02%    \n",
      "\n",
      "CPU times: user 1min 23s, sys: 9.48 s, total: 1min 33s\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >product_type</th>        <th class=\"col_heading level0 col1\" >count</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1-score</th>        <th class=\"col_heading level0 col5\" >roc_auc</th>        <th class=\"col_heading level0 col6\" >pr_auc</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col0\" class=\"data row0 col0\" >No Product</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col1\" class=\"data row0 col1\" >1,889,134</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col2\" class=\"data row0 col2\" >100.00%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col3\" class=\"data row0 col3\" >99.77%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col4\" class=\"data row0 col4\" >99.88%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col5\" class=\"data row0 col5\" >99.95%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row0_col6\" class=\"data row0 col6\" >99.98%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col0\" class=\"data row1 col0\" >Rental Only</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col1\" class=\"data row1 col1\" >23,909</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col2\" class=\"data row1 col2\" >23.38%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col3\" class=\"data row1 col3\" >98.01%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col4\" class=\"data row1 col4\" >37.75%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col5\" class=\"data row1 col5\" >99.03%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row1_col6\" class=\"data row1 col6\" >43.61%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col0\" class=\"data row2 col0\" >Home Only</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col1\" class=\"data row2 col1\" >22,848</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col2\" class=\"data row2 col2\" >15.19%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col3\" class=\"data row2 col3\" >81.89%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col4\" class=\"data row2 col4\" >25.63%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col5\" class=\"data row2 col5\" >97.86%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row2_col6\" class=\"data row2 col6\" >29.16%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col0\" class=\"data row3 col0\" >Auto Only</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col1\" class=\"data row3 col1\" >212,384</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col2\" class=\"data row3 col2\" >71.48%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col3\" class=\"data row3 col3\" >44.51%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col4\" class=\"data row3 col4\" >54.86%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col5\" class=\"data row3 col5\" >97.10%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row3_col6\" class=\"data row3 col6\" >72.48%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col0\" class=\"data row4 col0\" >Auto + Rental</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col1\" class=\"data row4 col1\" >123,821</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col2\" class=\"data row4 col2\" >56.73%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col3\" class=\"data row4 col3\" >47.13%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col4\" class=\"data row4 col4\" >51.49%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col5\" class=\"data row4 col5\" >96.17%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row4_col6\" class=\"data row4 col6\" >56.21%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col0\" class=\"data row5 col0\" >Auto + Home</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col1\" class=\"data row5 col1\" >294,754</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col2\" class=\"data row5 col2\" >82.44%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col3\" class=\"data row5 col3\" >62.53%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col4\" class=\"data row5 col4\" >71.12%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col5\" class=\"data row5 col5\" >98.68%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row5_col6\" class=\"data row5 col6\" >87.59%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col0\" class=\"data row6 col0\" >MACRO</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col1\" class=\"data row6 col1\" >2,566,850</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col2\" class=\"data row6 col2\" >58.20%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col3\" class=\"data row6 col3\" >72.31%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col4\" class=\"data row6 col4\" >56.79%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col5\" class=\"data row6 col5\" >94.03%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row6_col6\" class=\"data row6 col6\" >64.84%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col0\" class=\"data row7 col0\" >MICRO</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col1\" class=\"data row7 col1\" >2,566,850</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col2\" class=\"data row7 col2\" >88.21%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col3\" class=\"data row7 col3\" >88.21%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col4\" class=\"data row7 col4\" >88.21%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col5\" class=\"data row7 col5\" >99.33%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row7_col6\" class=\"data row7 col6\" >97.10%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col0\" class=\"data row8 col0\" >WEIGHT</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col1\" class=\"data row8 col1\" >2,566,850</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col2\" class=\"data row8 col2\" >92.07%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col3\" class=\"data row8 col3\" >88.21%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col4\" class=\"data row8 col4\" >89.28%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col5\" class=\"data row8 col5\" >97.77%</td>\n",
       "                        <td id=\"T_25ecfda6_e0bc_11eb_9b01_7922bef9b8e8row8_col6\" class=\"data row8 col6\" >93.02%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f1e2f8419b0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print()\n",
    "print(\"********  model performance in validation set **********  \\n \")\n",
    "print()\n",
    "    \n",
    "fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, val_loader, multi_label, device, weight, n_classes)\n",
    "metrics_dict, roc_auc, pr_auc = evaluate(fin_outputs, fin_targets)\n",
    "\n",
    "print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "print()\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "              \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "             \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "              \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "             \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "              \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "             \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))\n",
    "\n",
    "print()\n",
    "n_classes=th.unique(multi_label).shape[0]\n",
    "label_map={0:\"No Product\",1:\"Rental Only\",2:\"Home Only\",3:\"Auto Only\",4:\"Auto + Rental\",5:\"Auto + Home\"}\n",
    "\n",
    "report=metrics.classification_report(fin_targets.squeeze(), fin_outputs.argmax(axis=1), output_dict=True)\n",
    "\n",
    "table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "table[\"count\"]=table[\"support\"].astype(int)\n",
    "table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "table[\"product_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "table=table[['product_type','count','precision','recall','f1-score','roc_auc','pr_auc']]\n",
    "\n",
    "total=table['count'].sum()\n",
    "\n",
    "table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],\\\n",
    "                        metrics_dict['auc_macro_ovo'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],\\\n",
    "                            metrics_dict['auc_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],\\\n",
    "                        metrics_dict['auc_weighted_ovo'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "table.style.format({\"count\":\"{:,}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"roc_auc\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/251 [00:00<00:22, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********  model performance in test set **********  \n",
      " \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 251/251 [00:21<00:00, 11.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy            88.22%    \n",
      "\n",
      "precision(macro):   58.20%    recall(macro):  72.34%    f1-score(macro):  56.80%    ROC-AUC(macro):  94.05%    PR-AUC(macro):  64.74%    \n",
      "precision(micro):   88.22%    recall(micro):  88.22%    f1-score(micro):  88.22%    ROC-AUC(micro):  99.33%    PR-AUC(micro):  97.10%    \n",
      "precision(weight):  92.06%    recall(weight): 88.22%    f1-score(weight): 89.29%    ROC-AUC(weight): 97.78%    PR-AUC(weight): 93.01%    \n",
      "\n",
      "CPU times: user 1min, sys: 4.31 s, total: 1min 5s\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >product_type</th>        <th class=\"col_heading level0 col1\" >count</th>        <th class=\"col_heading level0 col2\" >precision</th>        <th class=\"col_heading level0 col3\" >recall</th>        <th class=\"col_heading level0 col4\" >f1-score</th>        <th class=\"col_heading level0 col5\" >roc_auc</th>        <th class=\"col_heading level0 col6\" >pr_auc</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col0\" class=\"data row0 col0\" >No Product</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col1\" class=\"data row0 col1\" >1,889,134</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col2\" class=\"data row0 col2\" >100.00%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col3\" class=\"data row0 col3\" >99.77%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col4\" class=\"data row0 col4\" >99.89%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col5\" class=\"data row0 col5\" >99.95%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row0_col6\" class=\"data row0 col6\" >99.99%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col0\" class=\"data row1 col0\" >Rental Only</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col1\" class=\"data row1 col1\" >23,909</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col2\" class=\"data row1 col2\" >23.46%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col3\" class=\"data row1 col3\" >98.08%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col4\" class=\"data row1 col4\" >37.86%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col5\" class=\"data row1 col5\" >99.03%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row1_col6\" class=\"data row1 col6\" >43.28%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col0\" class=\"data row2 col0\" >Home Only</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col1\" class=\"data row2 col1\" >22,847</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col2\" class=\"data row2 col2\" >15.24%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col3\" class=\"data row2 col3\" >82.07%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col4\" class=\"data row2 col4\" >25.71%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col5\" class=\"data row2 col5\" >97.88%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row2_col6\" class=\"data row2 col6\" >28.88%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col0\" class=\"data row3 col0\" >Auto Only</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col1\" class=\"data row3 col1\" >212,383</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col2\" class=\"data row3 col2\" >71.60%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col3\" class=\"data row3 col3\" >44.62%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col4\" class=\"data row3 col4\" >54.98%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col5\" class=\"data row3 col5\" >97.11%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row3_col6\" class=\"data row3 col6\" >72.54%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col0\" class=\"data row4 col0\" >Auto + Rental</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col1\" class=\"data row4 col1\" >123,821</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col2\" class=\"data row4 col2\" >56.49%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col3\" class=\"data row4 col3\" >46.85%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col4\" class=\"data row4 col4\" >51.22%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col5\" class=\"data row4 col5\" >96.17%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row4_col6\" class=\"data row4 col6\" >56.20%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col0\" class=\"data row5 col0\" >Auto + Home</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col1\" class=\"data row5 col1\" >294,754</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col2\" class=\"data row5 col2\" >82.41%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col3\" class=\"data row5 col3\" >62.62%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col4\" class=\"data row5 col4\" >71.16%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col5\" class=\"data row5 col5\" >98.68%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row5_col6\" class=\"data row5 col6\" >87.53%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col0\" class=\"data row6 col0\" >MACRO</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col1\" class=\"data row6 col1\" >2,566,848</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col2\" class=\"data row6 col2\" >58.20%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col3\" class=\"data row6 col3\" >72.34%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col4\" class=\"data row6 col4\" >56.80%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col5\" class=\"data row6 col5\" >94.05%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row6_col6\" class=\"data row6 col6\" >64.74%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col0\" class=\"data row7 col0\" >MICRO</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col1\" class=\"data row7 col1\" >2,566,848</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col2\" class=\"data row7 col2\" >88.22%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col3\" class=\"data row7 col3\" >88.22%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col4\" class=\"data row7 col4\" >88.22%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col5\" class=\"data row7 col5\" >99.33%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row7_col6\" class=\"data row7 col6\" >97.10%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col0\" class=\"data row8 col0\" >WEIGHT</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col1\" class=\"data row8 col1\" >2,566,848</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col2\" class=\"data row8 col2\" >92.06%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col3\" class=\"data row8 col3\" >88.22%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col4\" class=\"data row8 col4\" >89.29%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col5\" class=\"data row8 col5\" >97.78%</td>\n",
       "                        <td id=\"T_4b056cc2_e0bc_11eb_9b01_7922bef9b8e8row8_col6\" class=\"data row8 col6\" >93.01%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f2a6f6d61d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "print()\n",
    "print(\"********  model performance in test set **********  \\n \")\n",
    "print()\n",
    "    \n",
    "fin_outputs, fin_targets, losses_tmp=eval_loop_func(model, test_loader, multi_label, device, weight, n_classes)\n",
    "metrics_dict, roc_auc, pr_auc = evaluate(fin_outputs, fin_targets)\n",
    "\n",
    "print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "print()\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "              \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "             \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "              \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "             \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "              \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "             \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))\n",
    "\n",
    "print()\n",
    "n_classes=th.unique(multi_label).shape[0]\n",
    "label_map={0:\"No Product\",1:\"Rental Only\",2:\"Home Only\",3:\"Auto Only\",4:\"Auto + Rental\",5:\"Auto + Home\"}\n",
    "\n",
    "report=metrics.classification_report(fin_targets.squeeze(), fin_outputs.argmax(axis=1), output_dict=True)\n",
    "\n",
    "table = pd.DataFrame(report).transpose().iloc[:n_classes,:]\n",
    "table[\"count\"]=table[\"support\"].astype(int)\n",
    "table[\"roc_auc\"]=[roc_auc[i] for i in range(n_classes)]\n",
    "table[\"pr_auc\"]=[pr_auc[i] for i in range(n_classes)]\n",
    "table[\"product_type\"]=[label_map[i] for i in range(n_classes)]\n",
    "table=table[['product_type','count','precision','recall','f1-score','roc_auc','pr_auc']]\n",
    "\n",
    "total=table['count'].sum()\n",
    "\n",
    "table.loc[len(table.index)]=[\"MACRO\",total,metrics_dict['prec_macro'],metrics_dict['recall_macro'],metrics_dict['fscore_macro'],\\\n",
    "                        metrics_dict['auc_macro_ovo'],metrics_dict['pr_auc_macro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"MICRO\",total,metrics_dict['prec_micro'],metrics_dict['recall_micro'],metrics_dict['fscore_micro'],\\\n",
    "                            metrics_dict['auc_micro'],metrics_dict['pr_auc_micro']]\n",
    "\n",
    "table.loc[len(table.index)]=[\"WEIGHT\",total,metrics_dict['prec_weighted'],metrics_dict['recall_weighted'],metrics_dict['fscore_weighted'],\\\n",
    "                        metrics_dict['auc_weighted_ovo'],metrics_dict['pr_auc_weighted']]\n",
    "\n",
    "table.style.format({\"count\":\"{:,}\",\"f1-score\":\"{:.2%}\",\"precision\":\"{:.2%}\",\"recall\":\"{:.2%}\",\"roc_auc\":\"{:.2%}\",\"pr_auc\":\"{:.2%}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if not os.path.exists(\"/mnt/bgnn/model_save/\"):\n",
    "    os.makedirs(\"/mnt/bgnn/model_save/\")\n",
    "th.save(model.state_dict(),\"/mnt/bgnn/model_save/Graph_Conv.pt\")\n",
    "!hdfs dfs -put -f /mnt/bgnn/model_save/Graph_Conv.pt  /dz/dz_6104/disc.db/BGNN/Graph_Conv.pt\n",
    "os.system(\"rm /mnt/bgnn/model_save/Graph_Conv.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/ubuntu\"\n",
    "if not os.path.isfile(os.path.join(path,\"Graph_Conv.pt\")):\n",
    "    !hdfs dfs -get  /dz/dz_6104/disc.db/BGNN/Graph_Conv.pt     /home/ubuntu\n",
    "\n",
    "\n",
    "model = Entity_Classify(G,\n",
    "                       feat_list,\n",
    "                       args.h_dim,\n",
    "                       n_classes,\n",
    "                       num_bases=args.num_bases,\n",
    "                       num_hidden_layers=args.num_layers,\n",
    "                       dropout=args.dropout,\n",
    "                       use_self_loop=args.use_self_loop)\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "model.load_state_dict(th.load(os.path.join(path,\"Graph_Conv.pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/251 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "DGLError",
     "evalue": "[08:53:25] /opt/dgl/src/array/cuda/array_op_impl.cu:91: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA kernel launch error: out of memory\nStack trace:\n  [bt] (0) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f2d6eb5d10f]\n  [bt] (1) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::BinaryElewise<(DLDeviceType)2, long, dgl::aten::arith::LT>(dgl::runtime::NDArray, long)+0x174) [0x7f2d6f3c3954]\n  [bt] (2) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::aten::LT(dgl::runtime::NDArray, long)+0x207) [0x7f2d6eb68017]\n  [bt] (3) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::HeteroGraph::HasVertices(unsigned long, dgl::runtime::NDArray) const+0xbb) [0x7f2d6f2a7dbb]\n  [bt] (4) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(+0xca7159) [0x7f2d6f2b9159]\n  [bt] (5) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f2d6f249aa8]\n  [bt] (6) /usr/local/anaconda/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f2e9e990ec0]\n  [bt] (7) /usr/local/anaconda/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f2e9e99087d]\n  [bt] (8) /usr/local/anaconda/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f2e9eba6ede]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDGLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-6c41d1b41efc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mIDX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mH_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-69cf1e7929af>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_nodes, blocks)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usaanr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-40ff301914d6>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs)\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0minputs_src\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/nn/pytorch/hetero.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, g, inputs, mod_args, mod_kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0msrc_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                     \u001b[0;34m*\u001b[0m\u001b[0mmod_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     **mod_kwargs.get(etype, {}))\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdstdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/nn/pytorch/conv/graphconv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0mfeat_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_dst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_as_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_norm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'both'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m                 \u001b[0mdegs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m                 \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0mshp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeat_src\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mout_degrees\u001b[0;34m(self, u, etype)\u001b[0m\n\u001b[1;32m   3506\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrcnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3507\u001b[0m         \u001b[0mu_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3508\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3509\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'u contains invalid node IDs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3510\u001b[0m         \u001b[0mdeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'u'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mhas_nodes\u001b[0;34m(self, vid, ntype)\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All IDs must be non-negative integers.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m         ret = self._graph.has_nodes(\n\u001b[0;32m-> 2661\u001b[0;31m             self.get_ntype_id(ntype), vid_tensor)\n\u001b[0m\u001b[1;32m   2662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/heterograph_index.py\u001b[0m in \u001b[0;36mhas_nodes\u001b[0;34m(self, ntype, vids)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m    329\u001b[0m         return F.from_dgl_nd(_CAPI_DGLHeteroHasVertices(\n\u001b[0;32m--> 330\u001b[0;31m             self, int(ntype), F.to_dgl_nd(vids)))\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhas_edges_between\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/_ffi/_ctypes/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    188\u001b[0m         check_call(_LIB.DGLFuncCall(\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             ctypes.byref(ret_val), ctypes.byref(ret_tcode)))\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda/lib/python3.6/site-packages/dgl/_ffi/base.py\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \"\"\"\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDGLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDGLGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDGLError\u001b[0m: [08:53:25] /opt/dgl/src/array/cuda/array_op_impl.cu:91: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA kernel launch error: out of memory\nStack trace:\n  [bt] (0) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f2d6eb5d10f]\n  [bt] (1) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::runtime::NDArray dgl::aten::impl::BinaryElewise<(DLDeviceType)2, long, dgl::aten::arith::LT>(dgl::runtime::NDArray, long)+0x174) [0x7f2d6f3c3954]\n  [bt] (2) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::aten::LT(dgl::runtime::NDArray, long)+0x207) [0x7f2d6eb68017]\n  [bt] (3) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(dgl::HeteroGraph::HasVertices(unsigned long, dgl::runtime::NDArray) const+0xbb) [0x7f2d6f2a7dbb]\n  [bt] (4) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(+0xca7159) [0x7f2d6f2b9159]\n  [bt] (5) /usr/local/anaconda/lib/python3.6/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f2d6f249aa8]\n  [bt] (6) /usr/local/anaconda/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f2e9e990ec0]\n  [bt] (7) /usr/local/anaconda/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f2e9e99087d]\n  [bt] (8) /usr/local/anaconda/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f2e9eba6ede]\n\n"
     ]
    }
   ],
   "source": [
    "IDX_test=[]\n",
    "H_test=[]\n",
    "LOGIT_test=[]\n",
    "LABEL_test=[]\n",
    "for input_nodes_raw, seeds_raw, blocks in tqdm(test_loader, position=0, leave=True):\n",
    "    blocks = [blk.to(device) for blk in blocks]\n",
    "    seeds=seeds_raw.to(device)\n",
    "    input_nodes={}\n",
    "    input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "    input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "    model.eval()\n",
    "    logits,h = model(input_nodes,blocks)\n",
    "    IDX_test.append(seeds.detach().cpu().numpy().tolist())\n",
    "    H_test.append(h.detach().cpu().numpy().tolist())\n",
    "    LOGIT_test.append(logits.detach().cpu().numpy().tolist())\n",
    "    LABEL_test.append(multi_label[blocks[-1].dstdata[dgl.NID].cpu().numpy()].tolist())\n",
    "\n",
    "IDX_test=np.concatenate(IDX_test)\n",
    "H_test=np.concatenate(H_test)\n",
    "LOGIT_test=np.concatenate(LOGIT_test)\n",
    "LABEL_test=np.concatenate(LABEL_test)\n",
    "\n",
    "print(\"Logit Dimension is {:}\".format(LOGIT_test.shape))\n",
    "print(\"Label Dimension is {:}\".format(LABEL_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if not os.path.exists(\"/mnt/bgnn/model_save/\"):\n",
    "    os.makedirs(\"/mnt/bgnn/model_save/\")\n",
    "savez_compressed(\"/mnt/bgnn/model_save/Graph_Conv_LOGIT.npz\", LOGIT_test)\n",
    "savez_compressed(\"/mnt/bgnn/model_save/Graph_Conv_LABEL.npz\", LABEL_test)\n",
    "!hdfs dfs -put -f /mnt/bgnn/model_save/Graph_Conv_LOGIT.npz  /dz/dz_6104/disc.db/BGNN/Graph_Conv_LOGIT.npz\n",
    "!hdfs dfs -put -f /mnt/bgnn/model_save/Graph_Conv_LABEL.npz  /dz/dz_6104/disc.db/BGNN/Graph_Conv_LABEL.npz\n",
    "os.system(\"rm /mnt/bgnn/model_save/Graph_Conv_LOGIT.npz\")\n",
    "os.system(\"rm /mnt/bgnn/model_save/Graph_Conv_LABEL.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"/home/ubuntu\"\n",
    "if not os.path.isfile(os.path.join(path,\"Graph_Conv_LOGIT.npz\")):\n",
    "    !hdfs dfs -get  /dz/dz_6104/disc.db/BGNN/Graph_Conv_LOGIT.npz     /home/ubuntu\n",
    "    !hdfs dfs -get  /dz/dz_6104/disc.db/BGNN/Graph_Conv_LABEL.npz     /home/ubuntu\n",
    "\n",
    "fin_logits_graph = load(\"/home/ubuntu/Graph_Conv_LOGIT.npz\")['arr_0']\n",
    "fin_targets_graph = load(\"/home/ubuntu/Graph_Conv_LABEL.npz\")['arr_0']\n",
    "\n",
    "metrics_dict, roc_auc, pr_auc =evaluate(fin_logits_graph, fin_targets_graph.squeeze())\n",
    "print(\"\")\n",
    "print(\"==> Running Validation on validation set \\n\")\n",
    "print(\"\")\n",
    "\n",
    "print(\"{:<20}{:<10.2%}\".format(\"accuracy\", metrics_dict['acc']))\n",
    "print()\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(macro):\",metrics_dict['prec_macro'],\"recall(macro):\",metrics_dict['recall_macro'],\\\n",
    "              \"f1-score(macro):\",metrics_dict['fscore_macro'],\"ROC-AUC(macro):\",metrics_dict['auc_macro_ovo'],\\\n",
    "             \"PR-AUC(macro):\",metrics_dict['pr_auc_macro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(micro):\",metrics_dict['prec_micro'],\"recall(micro):\",metrics_dict['recall_micro'],\\\n",
    "              \"f1-score(micro):\",metrics_dict['fscore_micro'],\"ROC-AUC(micro):\",metrics_dict['auc_micro'],\\\n",
    "             \"PR-AUC(micro):\",metrics_dict['pr_auc_micro']))\n",
    "\n",
    "print(\"{:<20}{:<10,.2%}{:<16}{:<10,.2%}{:<18}{:<10,.2%}{:<17}{:<10,.2%}{:<16}{:<10,.2%}\"\\\n",
    "      .format(\"precision(weight):\",metrics_dict['prec_weighted'],\"recall(weight):\",metrics_dict['recall_weighted'],\\\n",
    "              \"f1-score(weight):\",metrics_dict['fscore_weighted'],\"ROC-AUC(weight):\",metrics_dict['auc_weighted_ovo'],\\\n",
    "             \"PR-AUC(weight):\",metrics_dict['pr_auc_weighted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sparsity rate of embedding vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=np.array(H)\n",
    "non_zero=np.count_nonzero(H)\n",
    "total_val=np.product(H.shape)\n",
    "sparsity=(total_val-non_zero)/total_val\n",
    "density=non_zero/total_val\n",
    "print(\"sparsity rate is {:.2%}\".format(sparsity))\n",
    "print(\"density rate is {:.2%}\".format(density))\n",
    "print(\"embedding vector shape is {}\".format(H.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_train=np.array(IDX)\n",
    "H_train=np.array(H)\n",
    "mask_train=np.array(['train']*len(IDX_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_val=[]\n",
    "H_val=[]\n",
    "LOGIT_val=[]\n",
    "LABEL_val=[]\n",
    "for input_nodes_raw, seeds_raw, blocks in tqdm(val_loader, position=0, leave=True):\n",
    "    blocks = [blk.to(device) for blk in blocks]\n",
    "    seeds=seeds_raw.to(device)\n",
    "    input_nodes={}\n",
    "    input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "    input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "    model.eval()\n",
    "    logits,h = model(input_nodes,blocks)\n",
    "    IDX_val.append(seeds.detach().cpu().numpy().tolist())\n",
    "    H_val.append(h.detach().cpu().numpy().tolist())\n",
    "    LOGIT_val.append(logits.detach().cpu().numpy().tolist())\n",
    "    LABEL_val.append(multi_label[blocks[-1].dstdata[dgl.NID].cpu().numpy()].tolist())\n",
    "\n",
    "IDX_val=np.concatenate(IDX_val)\n",
    "H_val=np.concatenate(H_val)\n",
    "LOGIT_val=np.concatenate(LOGIT_val)\n",
    "LABEL_val=np.concatenate(LABEL_val)\n",
    "mask_val=np.array(['val']*len(IDX_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX_test=[]\n",
    "H_test=[]\n",
    "LOGIT_test=[]\n",
    "LABEL_test=[]\n",
    "for input_nodes_raw, seeds_raw, blocks in tqdm(test_loader, position=0, leave=True):\n",
    "    blocks = [blk.to(device) for blk in blocks]\n",
    "    seeds=seeds_raw.to(device)\n",
    "    input_nodes={}\n",
    "    input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "    input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "    model.eval()\n",
    "    logits,h = model(input_nodes,blocks)\n",
    "    IDX_test.append(seeds.detach().cpu().numpy().tolist())\n",
    "    H_test.append(h.detach().cpu().numpy().tolist())\n",
    "    LOGIT_test.append(logits.detach().cpu().numpy().tolist())\n",
    "    LABEL_test.append(multi_label[blocks[-1].dstdata[dgl.NID].cpu().numpy()].tolist())\n",
    "\n",
    "IDX_test=np.concatenate(IDX_test)\n",
    "H_test=np.concatenate(H_test)\n",
    "LOGIT_test=np.concatenate(LOGIT_test)\n",
    "LABEL_test=np.concatenate(LABEL_test)\n",
    "mask_test=np.array(['test']*len(IDX_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX=np.concatenate((IDX_train,IDX_val, IDX_test))\n",
    "H=np.concatenate((H_train,H_val, H_test))\n",
    "mask=np.concatenate((mask_train,mask_val, mask_test))\n",
    "\n",
    "_idx=IDX.argsort()  #### sort the node id from 0 to max_num, so that it can be matched with LABEL\n",
    "embedding_vector=H[_idx]\n",
    "mask=mask[_idx]\n",
    "\n",
    "print(\"{:<30}{}\".format(\"shape of embedding vector\",embedding_vector.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# savez_compressed(\"embedding_vector.npz\",embedding_vector)\n",
    "# embedding_vector=load(\"embedding_vector.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# embedding_vector=load(\"embedding_vector.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization of embedding vectors for different categories of USAA Members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF=pd.DataFrame({\"IDX\":_idx.tolist(), \"MASK\":mask.tolist(), \"Product\":multi_label.squeeze().tolist()})\n",
    "prod_map={0:\"No Product\",1:\"Rental Only\",2:\"Home Only\",3:\"Auto Only\",4:\"Auto + Rental\",4:\"Auto + Home\"}\n",
    "DF['Product'] = list(map(prod_map.get, DF['Product']))\n",
    "\n",
    "N=1000\n",
    "\n",
    "train_df=DF[DF[\"MASK\"]==\"train\"]\n",
    "sample_df_train=train_df.groupby(['Product'], group_keys=False).apply(lambda x: x.sample(n=N,random_state=101))\n",
    "sample_id_train=sample_df_train[\"IDX\"].values\n",
    "# prod_sample_train=DF['Product'].values[sample_id_train]\n",
    "prod_sample_train=DF[DF[\"IDX\"].isin(sample_id_train)]['Product'].values\n",
    "embedding_sample_train=embedding_vector[DF[\"IDX\"].isin(sample_id_train)]\n",
    "\n",
    "val_df=DF[DF[\"MASK\"]==\"val\"]\n",
    "sample_df_val=val_df.groupby(['Product'], group_keys=False).apply(lambda x: x.sample(n=N,random_state=101))\n",
    "sample_id_val=sample_df_val[\"IDX\"].values\n",
    "# prod_sample_val=DF['Product'].values[sample_id_val]\n",
    "prod_sample_val=DF[DF[\"IDX\"].isin(sample_id_val)]['Product'].values\n",
    "embedding_sample_val=embedding_vector[DF[\"IDX\"].isin(sample_id_val)]\n",
    "\n",
    "test_df=DF[DF[\"MASK\"]==\"test\"]\n",
    "sample_df_test=test_df.groupby(['Product'], group_keys=False).apply(lambda x: x.sample(n=N,random_state=101))\n",
    "sample_id_test=sample_df_test[\"IDX\"].values\n",
    "# prod_sample_test=DF['Product'].values[sample_id_test]\n",
    "prod_sample_test=DF[DF[\"IDX\"].isin(sample_id_test)]['Product'].values\n",
    "embedding_sample_test=embedding_vector[DF[\"IDX\"].isin(sample_id_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.unique(prod_sample_train,return_counts=True)\n",
    "pd.DataFrame({\"Auto or Not\":a,\"sampled_#\":b}).style.format({'sampled_#':'{:,}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet scikit-learn\n",
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsne_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"t-SNE dimension reduction for training embedding vector:\")\n",
    "print()\n",
    "train_embedding = tsne_func.fit(embedding_sample_train)\n",
    "\n",
    "# savez_compressed(\"RGCN_train_embedding_tsne.npz\",train_embedding)\n",
    "# train_embedding=load(\"RGCN_train_embedding_tsne.npz\")['arr_0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 5)\n",
    "ax=sns.scatterplot(train_embedding[:,0], train_embedding[:,1], hue=prod_sample_train.squeeze(), legend='full', palette=palette)\n",
    "ax.set_title(\"Embedding Vectors t-SNE(sample=1000) \\n Training Set \",fontsize=15)\n",
    "# ax.set(ylim=(-15, 15))\n",
    "# ax.set(xlim=(-15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.unique(prod_sample_val,return_counts=True)\n",
    "pd.DataFrame({\"Auto or Not\":a,\"sampled_#\":b}).style.format({'sampled_#':'{:,}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"t-SNE dimension reduction for validation embedding:\")\n",
    "print()\n",
    "val_embedding = tsne_func.fit(embedding_sample_val)\n",
    "\n",
    "# savez_compressed(\"RGCN_val_embedding_tsne.npz\",val_embedding)\n",
    "# val_embedding=load(\"RGCN_val_embedding_tsne.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 2)\n",
    "ax=sns.scatterplot(val_embedding[:,0], val_embedding[:,1], hue=prod_sample_val.squeeze(), legend='full', palette=palette)\n",
    "ax.set_title(\"Embedding Vectors t-SNE (sample=1000) \\n Validation Set \",fontsize=15)\n",
    "# ax.set(ylim=(-20, None))\n",
    "# ax.set(xlim=(None, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b=np.unique(prod_sample_test,return_counts=True)\n",
    "pd.DataFrame({\"Auto or Not\":a,\"sampled_#\":b}).style.format({'sampled_#':'{:,}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"t-SNE dimension reduction for test embedding:\")\n",
    "print()\n",
    "test_embedding = tsne_func.fit(embedding_sample_test)\n",
    "\n",
    "# savez_compressed(\"RGCN_test_embedding_tsne.npz\",test_embedding)\n",
    "# test_embedding=load(\"RGCN_test_embedding_tsne.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})\n",
    "palette = sns.color_palette(\"bright\", 2)\n",
    "ax=sns.scatterplot(test_embedding[:,0], test_embedding[:,1], hue=prod_sample_test.squeeze(), legend='full', palette=palette)\n",
    "ax.set_title(\"Embedding Vectors t-SNE (sample=1000) \\n Test Set \",fontsize=15)\n",
    "# ax.set(ylim=(-20, None))\n",
    "# ax.set(xlim=(None, 25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
