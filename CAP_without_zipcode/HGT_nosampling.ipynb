{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --quiet --pre  dgl-cu101\n",
    "# !pip install --quiet torch==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is 1.6.0\n",
      "DGL version is 0.6a210127\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save,load,savetxt,loadtxt,savez_compressed\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook,tnrange\n",
    "tqdm.pandas(position=0, leave=True)\n",
    "import math \n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "from dgl.ops import edge_softmax\n",
    "\n",
    "from functools import partial\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize']=(5.0,4.0)\n",
    "plt.rcParams['image.interpolation']='nearest'\n",
    "plt.rcParams['image.cmap']='gray'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "import tsne_func\n",
    "print(\"torch version is {}\".format(th.__version__))\n",
    "print(\"DGL version is {}\".format(dgl.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "    th.cuda.manual_seed_all(seed)\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 13.5197 seconds to load graph\n"
     ]
    }
   ],
   "source": [
    "KG_dir=\"/workspace/cjiang/eagle_project/CAP_graph/dataset/\"\n",
    "start=time.time()\n",
    "with open(os.path.join(KG_dir,'CAP_Graph'), 'rb') as f:\n",
    "    G, node_labels = pickle.load(f)\n",
    "end=time.time()\n",
    "print(\"It took {:0.4f} seconds to load graph\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Node_types:  ['usaanr', 'zipcode']\n",
      "Edge_types:  ['AUTO_RELATED', 'Brother_Sister', 'Busi_rel_Other', 'Child', 'Ex-Spouse', 'Located_In', 'Parent', 'Pers_rel_Other', 'SPONSEE', 'SPONSOR', 'Spouse', 'Step-Child', 'Step-Parent', 'Location_of']\n",
      "**************************************************\n",
      "Canonical Etypes of Graph is:\n",
      "\n",
      "usaanr              AUTO_RELATED        usaanr              \n",
      "usaanr              Brother_Sister      usaanr              \n",
      "usaanr              Busi_rel_Other      usaanr              \n",
      "usaanr              Child               usaanr              \n",
      "usaanr              Ex-Spouse           usaanr              \n",
      "usaanr              Located_In          zipcode             \n",
      "usaanr              Parent              usaanr              \n",
      "usaanr              Pers_rel_Other      usaanr              \n",
      "usaanr              SPONSEE             usaanr              \n",
      "usaanr              SPONSOR             usaanr              \n",
      "usaanr              Spouse              usaanr              \n",
      "usaanr              Step-Child          usaanr              \n",
      "usaanr              Step-Parent         usaanr              \n",
      "zipcode             Location_of         usaanr              \n",
      "**************************************************\n",
      "number of ntype=usaanr                27,884,332     \n",
      "number of ntype=zipcode               37,158         \n",
      "**************************************************\n",
      "Total number of nodes is 27,921,490\n",
      "**************************************************\n",
      "number of etype=AUTO_RELATED          8,056,456      \n",
      "number of etype=Brother_Sister        618,666        \n",
      "number of etype=Busi_rel_Other        1,022,064      \n",
      "number of etype=Child                 11,067,385     \n",
      "number of etype=Ex-Spouse             3,682,614      \n",
      "number of etype=Located_In            27,884,332     \n",
      "number of etype=Parent                11,067,385     \n",
      "number of etype=Pers_rel_Other        1,892,856      \n",
      "number of etype=SPONSEE               15,958,685     \n",
      "number of etype=SPONSOR               15,958,685     \n",
      "number of etype=Spouse                15,485,971     \n",
      "number of etype=Step-Child            1,165,991      \n",
      "number of etype=Step-Parent           1,165,991      \n",
      "number of etype=Location_of           27,884,332     \n",
      "**************************************************\n",
      "Total number of edges is 142,911,413\n",
      "**************************************************\n",
      "**************************************************\n",
      "The attributes for the node type=usaanr\n",
      "**************************************************\n",
      "type                                    torch.Size([27884332, 1])\n",
      "usaanr                                  torch.Size([27884332, 1])\n",
      "usaayr                                  torch.Size([27884332, 1])\n",
      "AGE_BAND                                torch.Size([27884332, 1])\n",
      "ORIGEL                                  torch.Size([27884332, 1])\n",
      "ELIG2                                   torch.Size([27884332, 1])\n",
      "cmpyelig                                torch.Size([27884332, 1])\n",
      "SEX                                     torch.Size([27884332, 1])\n",
      "MARST                                   torch.Size([27884332, 1])\n",
      "BRANCH                                  torch.Size([27884332, 1])\n",
      "ENLPAYGD                                torch.Size([27884332, 1])\n",
      "MILST                                   torch.Size([27884332, 1])\n",
      "MLIST_OrigStat                          torch.Size([27884332, 1])\n",
      "ACTCORP                                 torch.Size([27884332, 1])\n",
      "STATE                                   torch.Size([27884332, 1])\n",
      "Segment                                 torch.Size([27884332, 1])\n",
      "train_mask                              torch.Size([27884332, 1])\n",
      "val_mask                                torch.Size([27884332, 1])\n",
      "test_mask                               torch.Size([27884332, 1])\n",
      "**************************************************\n",
      "The attributes for the node type=zipcode\n",
      "**************************************************\n",
      "type                                    torch.Size([37158, 1])\n"
     ]
    }
   ],
   "source": [
    "utils.graph_show(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The features associated with USAA Member are\n",
      " \n",
      "usaayr\n",
      "AGE_BAND\n",
      "ORIGEL\n",
      "ELIG2\n",
      "cmpyelig\n",
      "SEX\n",
      "MARST\n",
      "BRANCH\n",
      "ENLPAYGD\n",
      "MILST\n",
      "MLIST_OrigStat\n",
      "ACTCORP\n",
      "STATE\n",
      "Segment\n"
     ]
    }
   ],
   "source": [
    "usaanr_feat=[]\n",
    "for key, scheme in G.node_attr_schemes(ntype=\"usaanr\").items():\n",
    "    usaanr_feat.append(key)\n",
    "usaanr_feat=[x for x in usaanr_feat if x not in ['type','usaanr','train_mask','val_mask','test_mask']]\n",
    "\n",
    "print()\n",
    "print(\"The features associated with USAA Member are\\n \")\n",
    "for i in usaanr_feat:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USAA Members Features Embedding\n",
    "class USAANR_Embedding(nn.Module):\n",
    "    def __init__(self,G,feature_size):\n",
    "        super(USAANR_Embedding,self).__init__()\n",
    "        self.G=G\n",
    "        self.feature_size=feature_size\n",
    "        ## Embedding matrices for features of nodes.\n",
    "        self.emb = nn.ModuleDict()\n",
    "        \n",
    "        \n",
    "        for i,col in enumerate(usaanr_feat):\n",
    "            self.emb[col]=nn.Embedding(G.nodes['usaanr'].data[col].max().item()+1, feature_size)\n",
    "        ## Embedding for the node of House Properties\n",
    "#         self.node_emb=nn.Embedding(G.filter_nodes(lambda nodes: (nodes.data['node_type'] == 0).squeeze(1),\\\n",
    "#                                        ntype='House_Properties').max().item() + 1, feature_size)\n",
    "        self.node_emb=nn.Embedding(2, feature_size)\n",
    "    \n",
    "    def forward(self,nid):\n",
    "        nid=nid.to(\"cpu\")\n",
    "        h=self.node_emb(self.G.nodes['usaanr'].data['type'][nid].squeeze(1).to(device))\n",
    "        extra_repr=[]\n",
    "        for i,col in enumerate(usaanr_feat):\n",
    "            ndata=self.G.nodes['usaanr'].data[col]\n",
    "            extra_repr.append(self.emb[col](ndata[nid].to(device)).squeeze(1))\n",
    "        return h + th.stack(extra_repr, 0).sum(0)\n",
    "\n",
    "## zipcode Embedding\n",
    "class Zipcode_Embedding(nn.Module):\n",
    "    def __init__(self,G,feature_size):\n",
    "        super(Zipcode_Embedding,self).__init__()\n",
    "        self.G=G\n",
    "        self.feature_size=feature_size\n",
    "        \n",
    "        ## Embedding for the node of zipcode.\n",
    "#         self.node_emb=nn.Embedding(G.filter_nodes(lambda nodes: (nodes.data['type'] == 1).squeeze(1),\\\n",
    "#                                        ntype='zipcode').max().item() + 1, feature_size)\n",
    "        self.node_emb=nn.Embedding(2, feature_size)\n",
    "    \n",
    "    def forward(self,nid):\n",
    "        nid=nid.to(\"cpu\")\n",
    "        h=self.node_emb(self.G.nodes['zipcode'].data['type'][nid].squeeze(1).to(device))\n",
    "        return h \n",
    "\n",
    "class HGTLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_dim,\n",
    "                 out_dim,\n",
    "                 node_dict,\n",
    "                 edge_dict,\n",
    "                 n_heads,\n",
    "                 dropout = 0.2,\n",
    "                 use_norm = False):\n",
    "        super(HGTLayer, self).__init__()\n",
    "\n",
    "        self.in_dim        = in_dim\n",
    "        self.out_dim       = out_dim\n",
    "        self.node_dict     = node_dict\n",
    "        self.edge_dict     = edge_dict\n",
    "        self.num_types     = len(node_dict)\n",
    "        self.num_relations = len(edge_dict)\n",
    "        self.total_rel     = self.num_types * self.num_relations * self.num_types\n",
    "        self.n_heads       = n_heads\n",
    "        self.d_k           = out_dim // n_heads\n",
    "        self.sqrt_dk       = math.sqrt(self.d_k)\n",
    "        self.att           = None\n",
    "\n",
    "        self.k_linears   = nn.ModuleList()\n",
    "        self.q_linears   = nn.ModuleList()\n",
    "        self.v_linears   = nn.ModuleList()\n",
    "        self.a_linears   = nn.ModuleList()\n",
    "        self.norms       = nn.ModuleList()\n",
    "        self.use_norm    = use_norm\n",
    "\n",
    "        for t in range(self.num_types):\n",
    "            self.k_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.q_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.v_linears.append(nn.Linear(in_dim,   out_dim))\n",
    "            self.a_linears.append(nn.Linear(out_dim,  out_dim))\n",
    "            if use_norm:\n",
    "                self.norms.append(nn.LayerNorm(out_dim))\n",
    "\n",
    "        self.relation_pri   = nn.Parameter(th.ones(self.num_relations, self.n_heads))\n",
    "        self.relation_att   = nn.Parameter(th.Tensor(self.num_relations, n_heads, self.d_k, self.d_k))\n",
    "        self.relation_msg   = nn.Parameter(th.Tensor(self.num_relations, n_heads, self.d_k, self.d_k))\n",
    "        self.skip           = nn.Parameter(th.ones(self.num_types))\n",
    "        self.drop           = nn.Dropout(dropout)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.relation_att)\n",
    "        nn.init.xavier_uniform_(self.relation_msg)\n",
    "\n",
    "    def forward(self, G, h):\n",
    "        with G.local_scope():\n",
    "            node_dict, edge_dict = self.node_dict, self.edge_dict\n",
    "            for srctype, etype, dsttype in G.canonical_etypes:\n",
    "                sub_graph = G[srctype, etype, dsttype]\n",
    "\n",
    "                k_linear = self.k_linears[node_dict[srctype]]\n",
    "                v_linear = self.v_linears[node_dict[srctype]]\n",
    "                q_linear = self.q_linears[node_dict[dsttype]]\n",
    "\n",
    "                k = k_linear(h[srctype]).view(-1, self.n_heads, self.d_k)\n",
    "                v = v_linear(h[srctype]).view(-1, self.n_heads, self.d_k)\n",
    "                q = q_linear(h[dsttype]).view(-1, self.n_heads, self.d_k)\n",
    "\n",
    "                e_id = self.edge_dict[etype]\n",
    "\n",
    "                relation_att = self.relation_att[e_id]\n",
    "                relation_pri = self.relation_pri[e_id]\n",
    "                relation_msg = self.relation_msg[e_id]\n",
    "\n",
    "                k = th.einsum(\"bij,ijk->bik\", k, relation_att)\n",
    "                v = th.einsum(\"bij,ijk->bik\", v, relation_msg)\n",
    "\n",
    "                sub_graph.srcdata['k'] = k\n",
    "                sub_graph.dstdata['q'] = q\n",
    "                sub_graph.srcdata['v'] = v\n",
    "\n",
    "                sub_graph.apply_edges(fn.v_dot_u('q', 'k', 't'))\n",
    "                attn_score = sub_graph.edata.pop('t').sum(-1) * relation_pri / self.sqrt_dk\n",
    "                attn_score = edge_softmax(sub_graph, attn_score, norm_by='dst')\n",
    "\n",
    "                sub_graph.edata['t'] = attn_score.unsqueeze(-1)\n",
    "\n",
    "            G.multi_update_all({etype : (fn.u_mul_e('v', 't', 'm'), fn.sum('m', 't')) \\\n",
    "                                for etype in edge_dict}, cross_reducer = 'mean')\n",
    "\n",
    "            new_h = {}\n",
    "            for ntype in G.ntypes:\n",
    "                '''\n",
    "                    Step 3: Target-specific Aggregation\n",
    "                    x = norm( W[node_type] * gelu( Agg(x) ) + x )\n",
    "                '''\n",
    "                n_id = node_dict[ntype]\n",
    "                alpha = th.sigmoid(self.skip[n_id])\n",
    "                t = G.nodes[ntype].data['t'].view(-1, self.out_dim)\n",
    "                trans_out = self.drop(self.a_linears[n_id](t))\n",
    "                trans_out = trans_out * alpha + h[ntype] * (1-alpha)\n",
    "                if self.use_norm:\n",
    "                    new_h[ntype] = self.norms[n_id](trans_out)\n",
    "                else:\n",
    "                    new_h[ntype] = trans_out\n",
    "            return new_h\n",
    "        \n",
    "class HGT(nn.Module):\n",
    "    def __init__(self, G, node_dict, edge_dict, in_feat, h_dim, out_feat, n_layers, n_heads, use_norm = True):\n",
    "        super(HGT, self).__init__()\n",
    "        self.G=G\n",
    "        self.node_dict = node_dict\n",
    "        self.edge_dict = edge_dict\n",
    "        self.gcs = nn.ModuleList()\n",
    "        self.in_feat = in_feat\n",
    "        self.h_dim = h_dim\n",
    "        self.out_feat = out_feat\n",
    "        self.n_layers = n_layers\n",
    "        self.adapt_ws  = nn.ModuleList()\n",
    "        for t in range(len(node_dict)):\n",
    "            self.adapt_ws.append(nn.Linear(in_feat,   h_dim))\n",
    "        for _ in range(n_layers):\n",
    "            self.gcs.append(HGTLayer(h_dim, h_dim, node_dict, edge_dict, n_heads, use_norm = use_norm))\n",
    "        self.out = nn.Linear(h_dim, out_feat)\n",
    "        \n",
    "        self.node_embed=nn.ModuleDict()\n",
    "        self.node_embed['usaanr'] = USAANR_Embedding(self.G,self.in_feat)\n",
    "        self.node_embed['zipcode'] = Zipcode_Embedding(self.G,self.in_feat)\n",
    "           \n",
    "    def forward(self, G, out_key):\n",
    "        H = {}\n",
    "        for ntype in G.ntypes:\n",
    "            nid = th.arange(G.num_nodes(ntype))\n",
    "            H[ntype] = F.gelu(self.adapt_ws[self.node_dict[ntype]](self.node_embed[ntype](nid)))\n",
    "        \n",
    "        for layer in self.gcs:\n",
    "            H = layer(self.G, H)\n",
    "\n",
    "        return self.out(H[out_key]), H[out_key]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create subgraph for the purpose of preliminary test\n",
    "# dict_nodes={\"usaanr\":th.arange(G.num_nodes('usaanr'))[0:1000],'zipcode':th.arange(G.num_nodes('zipcode'))[0:100]}\n",
    "# sg=dgl.node_subgraph(G,dict_nodes)\n",
    "\n",
    "# dict_edges={}\n",
    "# for etype in G.etypes:\n",
    "#     dict_edges[etype]=th.arange(G.num_edges(etype))[0:5000]\n",
    "# sg=dgl.edge_subgraph(G,dict_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.graph_show(sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg.nodes['usaanr'].data[\"_ID\"].numpy().shape,  node_labels.shape, node_labels[sg.nodes['usaanr'].data[\"_ID\"]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=1024, clip=1.0, dropout=0.2, fanout=None, gpu=0, h_dim=64, l2norm=0.001, lr=0.001, max_lr=0.001, model_path='/workspace/cjiang/eagle_project/CAP_graph/hgt_model_param.pt', n_epochs=20, num_layers=1, num_mini_batch=8, num_worker=4, out_dim=1, seed=101)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='HGT')\n",
    "parser.add_argument(\"--dropout\", type=float, default=0,\n",
    "        help=\"dropout probability\")\n",
    "parser.add_argument(\"--h_dim\", type=int, default=128,\n",
    "        help=\"number of hidden units\")\n",
    "parser.add_argument(\"--out_dim\", type=int, default=1,\n",
    "        help=\"output dimension\")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "        help=\"gpu\")\n",
    "parser.add_argument(\"--lr\", type=float, default=1e-5,\n",
    "        help=\"learning rate\")\n",
    "parser.add_argument('--clip',    type=int, default=1.0) \n",
    "parser.add_argument('--max_lr',  type=float, default=1e-3) \n",
    "\n",
    "parser.add_argument(\"--num_layers\", type=int, default=1,\n",
    "        help=\"number of propagation rounds\")\n",
    "parser.add_argument(\"-e\", \"--n_epochs\", type=int, default=1,\n",
    "        help=\"number of training epochs\")\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"/workspace/cjiang/eagle_project/CAP_graph/hgt_model_param.pt\",\n",
    "        help='path for save the model')\n",
    "parser.add_argument(\"--l2norm\", type=float, default=0,\n",
    "        help=\"l2 norm coef\")\n",
    "\n",
    "parser.add_argument(\"--batch-size\", type=int, default=1024,\n",
    "        help=\"Mini-batch size. If -1, use full graph training.\")\n",
    "parser.add_argument(\"--num_mini_batch\", type=int, default=8,\n",
    "        help=\"Number of minibatch.\")\n",
    "parser.add_argument(\"--fanout\", type=int, default=None,\n",
    "        help=\"Fan-out of neighbor sampling.\")\n",
    "\n",
    "parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "        help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "\n",
    "parser.add_argument(\"--num_worker\",  type=int,default=4,  \n",
    "        help=\"number of worker for neighbor sampling\") \n",
    "\n",
    "args,unknown=parser.parse_known_args()\n",
    "\n",
    "args.num_layers=1\n",
    "args.dropout=0.2\n",
    "args.lr=1e-3\n",
    "args.l2norm=1e-3\n",
    "args.n_epochs=20\n",
    "args.h_dim=64\n",
    "args.batch_size=1024\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### setting up training, validation and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_803628e0_6192_11eb_93da_0242ac110006\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >label_class</th>        <th class=\"col_heading level0 col1\" >count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row0_col1\" class=\"data row0 col1\" >20,500,666</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row1_col0\" class=\"data row1 col0\" >1</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row1_col1\" class=\"data row1 col1\" >262,009</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row2_col0\" class=\"data row2 col0\" >2</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row2_col1\" class=\"data row2 col1\" >226,935</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row3_col0\" class=\"data row3 col0\" >3</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row3_col1\" class=\"data row3 col1\" >2,767</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row4_col0\" class=\"data row4 col0\" >4</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row4_col1\" class=\"data row4 col1\" >2,435,787</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row5_col0\" class=\"data row5 col0\" >5</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row5_col1\" class=\"data row5 col1\" >1,461,264</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row6_col0\" class=\"data row6 col0\" >6</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row6_col1\" class=\"data row6 col1\" >2,938,245</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_803628e0_6192_11eb_93da_0242ac110006level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row7_col0\" class=\"data row7 col0\" >7</td>\n",
       "                        <td id=\"T_803628e0_6192_11eb_93da_0242ac110006row7_col1\" class=\"data row7 col1\" >56,659</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f967088b320>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rels=len(G.etypes)\n",
    "# LABEL=th.tensor(node_labels[sg.nodes['usaanr'].data[\"_ID\"]]).long()\n",
    "LABEL=th.tensor(node_labels).long()\n",
    "labels, count=th.unique(LABEL,return_counts=True)\n",
    "num_classes=labels.shape[0]\n",
    "pd.DataFrame({\"label_class\":labels, \"count\":count}).style.format({'count':'{:,}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set    22,307,469\n",
      "validation set  2,788,435 \n",
      "test set        2,788,428 \n"
     ]
    }
   ],
   "source": [
    "train_mask=G.nodes[\"usaanr\"].data.pop('train_mask')\n",
    "val_mask=G.nodes[\"usaanr\"].data.pop('val_mask')\n",
    "test_mask=G.nodes[\"usaanr\"].data.pop('test_mask')\n",
    "\n",
    "train_idx=th.nonzero(train_mask.squeeze(1)).numpy()\n",
    "val_idx=th.nonzero(val_mask.squeeze(1)).numpy()\n",
    "test_idx=th.nonzero(test_mask.squeeze(1)).numpy()\n",
    "\n",
    "train_idx=th.from_numpy(train_idx).squeeze(1)    \n",
    "val_idx=th.from_numpy(val_idx).squeeze(1)    \n",
    "test_idx=th.from_numpy(test_idx).squeeze(1)\n",
    "\n",
    "train_label=LABEL[train_idx]\n",
    "val_label=LABEL[val_idx]\n",
    "test_label=LABEL[test_idx]\n",
    "\n",
    "print('{:<15} {:<10,}'.format(\"Training set\",train_idx.shape[0]))\n",
    "print('{:<15} {:<10,}'.format(\"validation set\",val_idx.shape[0]))\n",
    "print('{:<15} {:<10,}'.format(\"test set\",test_idx.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_idx.shape[0]+val_idx.shape[0]+test_idx.shape[0] == G.num_nodes('usaanr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "##### check cuda\n",
    "device=\"cpu\"\n",
    "# use_cuda=args.gpu>=0 and th.cuda.is_available()\n",
    "# if use_cuda:\n",
    "#     th.cuda.set_device(args.gpu)\n",
    "#     device='cuda:%d' % args.gpu\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'usaanr': 0, 'zipcode': 1}\n",
      "{'AUTO_RELATED': 0, 'Brother_Sister': 1, 'Busi_rel_Other': 2, 'Child': 3, 'Ex-Spouse': 4, 'Located_In': 5, 'Parent': 6, 'Pers_rel_Other': 7, 'SPONSEE': 8, 'SPONSOR': 9, 'Spouse': 10, 'Step-Child': 11, 'Step-Parent': 12, 'Location_of': 13}\n"
     ]
    }
   ],
   "source": [
    "node_dict = {}\n",
    "edge_dict = {}\n",
    "for ntype in G.ntypes:\n",
    "    node_dict[ntype] = len(node_dict)\n",
    "for etype in G.etypes:\n",
    "    edge_dict[etype] = len(edge_dict)\n",
    "    G.edges[etype].data['id'] = th.ones(G.number_of_edges(etype), dtype=th.long) * edge_dict[etype] \n",
    "\n",
    "print(node_dict)\n",
    "print(edge_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUTO_RELATED   id        0         \n",
      "Brother_Sister id        1         \n",
      "Busi_rel_Other id        2         \n",
      "Child          id        3         \n",
      "Ex-Spouse      id        4         \n",
      "Located_In     id        5         \n",
      "Parent         id        6         \n",
      "Pers_rel_Other id        7         \n",
      "SPONSEE        id        8         \n",
      "SPONSOR        id        9         \n",
      "Spouse         id        10        \n",
      "Step-Child     id        11        \n",
      "Step-Parent    id        12        \n",
      "Location_of    id        13        \n"
     ]
    }
   ],
   "source": [
    "for etype in G.etypes:\n",
    "    for key,val in G.edges[etype].data.items():\n",
    "        if key==\"id\":\n",
    "            print(\"{:<15}{:<10}{:<10}\".format(etype,key,th.unique(val).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): HGTLayer(\n",
       "    (k_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (q_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (v_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (a_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (1): HGTLayer(\n",
       "    (k_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (q_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (v_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (a_linears): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "\n",
    "model = HGT(G,\n",
    "            node_dict, \n",
    "            edge_dict,\n",
    "            in_feat=args.h_dim,\n",
    "            h_dim=args.h_dim,\n",
    "            out_feat=num_classes,\n",
    "            n_layers=2,\n",
    "            n_heads=4,\n",
    "            use_norm = True)\n",
    "\n",
    "# if use_cuda:\n",
    "#     model.cuda()\n",
    "\n",
    "model.gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.l2norm)\n",
    "optimizer = th.optim.AdamW(model.parameters())\n",
    "scheduler = th.optim.lr_scheduler.OneCycleLR(optimizer, total_steps=args.n_epochs, max_lr = args.max_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total # of parameter is 151,740\n"
     ]
    }
   ],
   "source": [
    "print(\"The total # of parameter is {:,}\".format(sum([p.nelement() for p in model.parameters()]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcs.0.relation_pri                                                    56             \n",
      "gcs.0.relation_att                                                    14,336         \n",
      "gcs.0.relation_msg                                                    14,336         \n",
      "gcs.0.skip                                                            2              \n",
      "gcs.0.k_linears.0.weight                                              4,096          \n",
      "gcs.0.k_linears.0.bias                                                64             \n",
      "gcs.0.k_linears.1.weight                                              4,096          \n",
      "gcs.0.k_linears.1.bias                                                64             \n",
      "gcs.0.q_linears.0.weight                                              4,096          \n",
      "gcs.0.q_linears.0.bias                                                64             \n",
      "gcs.0.q_linears.1.weight                                              4,096          \n",
      "gcs.0.q_linears.1.bias                                                64             \n",
      "gcs.0.v_linears.0.weight                                              4,096          \n",
      "gcs.0.v_linears.0.bias                                                64             \n",
      "gcs.0.v_linears.1.weight                                              4,096          \n",
      "gcs.0.v_linears.1.bias                                                64             \n",
      "gcs.0.a_linears.0.weight                                              4,096          \n",
      "gcs.0.a_linears.0.bias                                                64             \n",
      "gcs.0.a_linears.1.weight                                              4,096          \n",
      "gcs.0.a_linears.1.bias                                                64             \n",
      "gcs.0.norms.0.weight                                                  64             \n",
      "gcs.0.norms.0.bias                                                    64             \n",
      "gcs.0.norms.1.weight                                                  64             \n",
      "gcs.0.norms.1.bias                                                    64             \n",
      "gcs.1.relation_pri                                                    56             \n",
      "gcs.1.relation_att                                                    14,336         \n",
      "gcs.1.relation_msg                                                    14,336         \n",
      "gcs.1.skip                                                            2              \n",
      "gcs.1.k_linears.0.weight                                              4,096          \n",
      "gcs.1.k_linears.0.bias                                                64             \n",
      "gcs.1.k_linears.1.weight                                              4,096          \n",
      "gcs.1.k_linears.1.bias                                                64             \n",
      "gcs.1.q_linears.0.weight                                              4,096          \n",
      "gcs.1.q_linears.0.bias                                                64             \n",
      "gcs.1.q_linears.1.weight                                              4,096          \n",
      "gcs.1.q_linears.1.bias                                                64             \n",
      "gcs.1.v_linears.0.weight                                              4,096          \n",
      "gcs.1.v_linears.0.bias                                                64             \n",
      "gcs.1.v_linears.1.weight                                              4,096          \n",
      "gcs.1.v_linears.1.bias                                                64             \n",
      "gcs.1.a_linears.0.weight                                              4,096          \n",
      "gcs.1.a_linears.0.bias                                                64             \n",
      "gcs.1.a_linears.1.weight                                              4,096          \n",
      "gcs.1.a_linears.1.bias                                                64             \n",
      "gcs.1.norms.0.weight                                                  64             \n",
      "gcs.1.norms.0.bias                                                    64             \n",
      "gcs.1.norms.1.weight                                                  64             \n",
      "gcs.1.norms.1.bias                                                    64             \n",
      "adapt_ws.0.weight                                                     4,096          \n",
      "adapt_ws.0.bias                                                       64             \n",
      "adapt_ws.1.weight                                                     4,096          \n",
      "adapt_ws.1.bias                                                       64             \n",
      "out.weight                                                            512            \n",
      "out.bias                                                              8              \n",
      "node_embed.usaanr.emb.usaayr.weight                                   5,376          \n",
      "node_embed.usaanr.emb.AGE_BAND.weight                                 448            \n",
      "node_embed.usaanr.emb.ORIGEL.weight                                   2,624          \n",
      "node_embed.usaanr.emb.ELIG2.weight                                    384            \n",
      "node_embed.usaanr.emb.cmpyelig.weight                                 320            \n",
      "node_embed.usaanr.emb.SEX.weight                                      320            \n",
      "node_embed.usaanr.emb.MARST.weight                                    640            \n",
      "node_embed.usaanr.emb.BRANCH.weight                                   1,088          \n",
      "node_embed.usaanr.emb.ENLPAYGD.weight                                 1,600          \n",
      "node_embed.usaanr.emb.MILST.weight                                    512            \n",
      "node_embed.usaanr.emb.MLIST_OrigStat.weight                           192            \n",
      "node_embed.usaanr.emb.ACTCORP.weight                                  128            \n",
      "node_embed.usaanr.emb.STATE.weight                                    3,968          \n",
      "node_embed.usaanr.emb.Segment.weight                                  512            \n",
      "node_embed.usaanr.node_emb.weight                                     128            \n",
      "node_embed.zipcode.node_emb.weight                                    128            \n"
     ]
    }
   ],
   "source": [
    "param_dict={n: p.nelement() for n, p in model.named_parameters()}\n",
    "for i,j in param_dict.items():\n",
    "    print(\"{:<70}{:<15,}\".format(i,j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 92799056896 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7a96281ec188>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'usaanr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         loss = F.cross_entropy(logits, labels_train.squeeze(1),weight=th.Tensor([1,args.weight]).to(device))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a7aa12fda049>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, G, out_key)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a7aa12fda049>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, G, h)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             G.multi_update_all({etype : (fn.u_mul_e('v', 't', 'm'), fn.sum('m', 't')) \\\n\u001b[0;32m--> 125\u001b[0;31m                                 for etype in edge_dict}, cross_reducer = 'mean')\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mnew_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mmulti_update_all\u001b[0;34m(self, etype_dict, cross_reducer, apply_node_func)\u001b[0m\n\u001b[1;32m   4752\u001b[0m             \u001b[0;31m# merge by cross_reducer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4753\u001b[0m             self._node_frames[dtid].update(\n\u001b[0;32m-> 4754\u001b[0;31m                 reduce_dict_data(frames, cross_reducer, merge_order[dtid]))\n\u001b[0m\u001b[1;32m   4755\u001b[0m             \u001b[0;31m# apply\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4756\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mapply_node_func\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mreduce_dict_data\u001b[0;34m(frames, reducer, order)\u001b[0m\n\u001b[1;32m   5917\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfrm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5918\u001b[0m                 \u001b[0mflist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5919\u001b[0;31m         \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5920\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5921\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dgl/heterograph.py\u001b[0m in \u001b[0;36mmerger\u001b[0;34m(flist)\u001b[0m\n\u001b[1;32m   5907\u001b[0m                            '\"sum\", \"max\", \"min\", \"mean\" or \"stack\".')\n\u001b[1;32m   5908\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmerger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5909\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mredfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mflist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5910\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5911\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfrm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/dgl/backend/pytorch/tensor.py\u001b[0m in \u001b[0;36mstack\u001b[0;34m(seq, dim)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes_or_sections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 92799056896 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# %pdb\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "train_step = 0\n",
    "\n",
    "# th.manual_seed(args.seed)\n",
    "# th.cuda.manual_seed(args.seed)\n",
    "# th.cuda.manual_seed_all(args.seed)\n",
    "# np.ranom.seed(args.seed)\n",
    "# random.seed(args.seed)\n",
    "# th.backends.cudnn.deterministic=True\n",
    "\n",
    "# for epoch in tqdm(range(0,args.n_epochs)):\n",
    "for epoch in range(0,args.n_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    H=[]\n",
    "    \n",
    "    #====================================#\n",
    "    #            Traning                 #\n",
    "    #====================================#\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    logits,h = model(G,'usaanr')\n",
    "    optimizer.zero_grad()\n",
    "#         loss = F.cross_entropy(logits, labels_train.squeeze(1),weight=th.Tensor([1,args.weight]).to(device))\n",
    "    loss = F.cross_entropy(logits[train_idx], LABEL[train_idx].squeeze().to(device))\n",
    "\n",
    "    loss.backward()\n",
    "    th.nn.utils.clip_grad_norm_(model.parameters(), args.clip)\n",
    "    optimizer.step()\n",
    "\n",
    "    train_step += 1\n",
    "    scheduler.step(train_step)\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        model.eval()\n",
    "        logits,h = model(G,'usaanr')\n",
    "        pred   = logits.argmax(1).cpu()\n",
    "        train_acc = (pred[train_idx] == LABEL[train_idx]).float().mean()\n",
    "        val_acc   = (pred[val_idx]   == LABEL[val_idx]).float().mean()\n",
    "        test_acc  = (pred[test_idx]  == LABEL[test_idx]).float().mean()\n",
    "        if best_val_acc < val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_test_acc = test_acc\n",
    "            \n",
    "        t1 = time.time()\n",
    "        print('Epoch: %d | LR: %.5f | Loss %.4f | Train Acc %.4f | Val Acc %.4f | (Best %.4f) | Test Acc %.4f | (Best %.4f) | Elapsed: %.4f' % (\n",
    "            epoch,\n",
    "            optimizer.param_groups[0]['lr'], \n",
    "            loss.item(),\n",
    "            train_acc.item(),\n",
    "            val_acc.item(),\n",
    "            best_val_acc.item(),\n",
    "            test_acc.item(),\n",
    "            best_test_acc.item(),\n",
    "            t1-t0\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1571962240"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24561910*64/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24 * 2**20 * 64 * 4 / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073741824"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
