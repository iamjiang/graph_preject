{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections  import OrderedDict\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save,load,savetxt,loadtxt,savez_compressed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool, sum_models\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook,tnrange\n",
    "tqdm.pandas(position=0, leave=True)\n",
    "import math \n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl import edge_subgraph\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "\n",
    "from GraphSage_Model import *\n",
    "from evaluation import *\n",
    "from mask_function import *\n",
    "from MLP_Model import *\n",
    "from print_func import *\n",
    "\n",
    "from MLP_run import *\n",
    "from catboost_run import *\n",
    "from GraphSage_run import *\n",
    "from GraphSage_featureless_run import *\n",
    "\n",
    "import functools\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "\n",
    "print(\"torch version is {}\".format(th.__version__))\n",
    "print(\"DGL version is {}\".format(dgl.__version__))\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "    th.cuda.manual_seed_all(seed)\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    dgl.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='RGCN')\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.2,\n",
    "            help=\"dropout probability\")\n",
    "    parser.add_argument(\"--h_dim\", type=int, default=64,\n",
    "            help=\"number of hidden units\")\n",
    "#     parser.add_argument(\"--out_dim\", type=int, default=1,\n",
    "#             help=\"output dimension\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "            help=\"gpu\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3,\n",
    "            help=\"learning rate\")\n",
    "    parser.add_argument(\"--featureless_lr\", type=float, default=1e-4,\n",
    "            help='Learning Rate for featureless graph model')  \n",
    "    parser.add_argument(\"--num_bases\", type=int, default=5,\n",
    "            help=\"number of filter weight matrices, default: -1 [use all]\")\n",
    "    parser.add_argument(\"--num_layers\", type=int, default=1,\n",
    "            help=\"number of propagation rounds\")\n",
    "    parser.add_argument(\"-e\", \"--n_epochs\", type=int, default=5,\n",
    "            help=\"number of training epochs\")\n",
    "#     parser.add_argument(\"--model_path\", type=str, default=\"/workspace/cjiang/eagle_project/CAP_graph/CAP_without_zipcode/rgcn_model_param.pt\",\n",
    "#             help='path for save the model')\n",
    "    parser.add_argument(\"--l2norm\", type=float, default=1e-3,\n",
    "            help=\"l2 norm coef\")\n",
    "    parser.add_argument(\"--use_self_loop\", default=True, action='store_true',\n",
    "            help=\"include self feature as a special relation\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=10240,\n",
    "            help=\"Mini-batch size. If -1, use full graph training.\")\n",
    "    parser.add_argument(\"--fanout\", type=int, default=15,\n",
    "            help=\"Fan-out of neighbor sampling.\")\n",
    "    parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "            help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "    parser.add_argument(\"--loss_weight\",  type=bool,default=True,  ## number of label=0/number of label=1\n",
    "            help=\"weight for unbalance data\")\n",
    "    parser.add_argument(\"--num_worker\",  type=int,default=0,  \n",
    "            help=\"number of worker for neighbor sampling\") \n",
    "    parser.add_argument(\"--train_test_split\", type=float, default=0.1,\n",
    "            help=\"the proportion of test dataset\")\n",
    "    \n",
    "    parser.add_argument(\"--loss_function\", type=str, default=\"MultiClass\",\n",
    "            help='Loss function for Catboost')    \n",
    "    parser.add_argument(\"--CatBoost_LR\", type=float, default=0.01,\n",
    "            help='Learning Rate for Catboost')  \n",
    "    parser.add_argument(\"--iterations\", type=int, default=3000,\n",
    "            help='epochs iterations for Catboost')  \n",
    "    parser.add_argument(\"--early_stopping\", type=int, default=200,\n",
    "            help='early_stopping rounds for Catboost') \n",
    "    parser.add_argument(\"--device_type\", type=str, default=\"GPU\",\n",
    "            help='GPU utilization for Catboost training')      \n",
    "    parser.add_argument(\"--verbose\", type=int, default=200,\n",
    "            help='verbose details for Catboost training')  \n",
    "    \n",
    "    args,_=parser.parse_known_args()\n",
    "    \n",
    "    args.h_dim=32\n",
    "    args.batch_size=10240\n",
    "    args.train_test_split=0.10\n",
    "    args.n_epochs=3\n",
    "    print(args)\n",
    "\n",
    "    print()\n",
    "    \n",
    "    seed_everything(args.seed)\n",
    "    \n",
    "\n",
    "    KG_dir=\"/workspace/cjiang/eagle_project/CAP_graph/BGNN/\"\n",
    "\n",
    "    start=time.time()\n",
    "    with open(os.path.join(KG_dir,'CAP_Graph_v1'), 'rb') as f:\n",
    "        FG,multi_label,binary_label,\\\n",
    "        train_mask_multi_label,  val_mask_multi_label,  test_mask_multi_label,\\\n",
    "        train_mask_binary_label, val_mask_binary_label, test_mask_binary_label= pickle.load(f)\n",
    "    end=time.time()\n",
    "    print(\"It took {:0.4f} seconds to load graph\".format(end-start))\n",
    "\n",
    "    usaanr_feat=[]\n",
    "    for key, scheme in FG.node_attr_schemes(ntype=\"usaanr\").items():\n",
    "        usaanr_feat.append(key)\n",
    "\n",
    "    usaanr_feat=[x for x in usaanr_feat if x not in \n",
    "                 ['usaanr','cmpyelig','ACTCORP','Segment','train_mask','val_mask','test_mask','label','_ID']]\n",
    "\n",
    "    print()\n",
    "    print(\"The features associated with USAA Member are\\n \")\n",
    "    for i in usaanr_feat:\n",
    "        print(i)\n",
    "    print()\n",
    "    \n",
    "    FG.nodes['usaanr'].data['label']=binary_label\n",
    "    \n",
    "#     dict_edges={}\n",
    "#     for etype in FG.etypes:\n",
    "#         dict_edges[etype]=th.arange(FG.num_edges(etype))[0:5000]\n",
    "#     sg=dgl.edge_subgraph(FG,dict_edges)\n",
    "#     G=copy.deepcopy(sg)\n",
    "    \n",
    "    G=copy.deepcopy(FG)\n",
    "    \n",
    "    graph_class=transductive_graph(G,args.train_test_split,args.seed)\n",
    "    G, train_mask, test_mask=graph_class.train_test_mask_func()\n",
    "    \n",
    "    assert th.nonzero(train_mask).shape[0] + th.nonzero(test_mask).shape[0]==G.num_nodes()\n",
    "    \n",
    "    device=\"cpu\"\n",
    "    use_cuda=args.gpu>=0 and th.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        th.cuda.set_device(args.gpu)\n",
    "        device='cuda:%d' % args.gpu\n",
    "    \n",
    "    data=G, train_mask, test_mask\n",
    "    \n",
    "    %pdb\n",
    "    train_graph_v1, test_graph_v1=graph_run_featureless(args,usaanr_feat,device,data)    \n",
    "    train_graph_v2, test_graph_v2=graph_run(args,usaanr_feat,device,data)\n",
    "    train_catboost, test_catboost=catboost_run(args,device,data)\n",
    "    train_mlp, test_mlp=MLP_run(args,usaanr_feat,device,data)\n",
    "    \n",
    "    print()\n",
    "    func_print(train_catboost, train_mlp, train_graph_v1, train_graph_v2, \"train_output.txt\")\n",
    "    print()\n",
    "    func_print(test_catboost, test_mlp, test_graph_v1, test_graph_v2, \"test_output.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
