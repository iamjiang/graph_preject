{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version is 1.7.0\n",
      "DGL version is 0.8a210831\n"
     ]
    }
   ],
   "source": [
    "from collections  import OrderedDict\n",
    "import copy\n",
    "import argparse\n",
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import save,load,savetxt,loadtxt,savez_compressed\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, f1_score,average_precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support \n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc as auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool, sum_models\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook,tnrange\n",
    "tqdm.pandas(position=0, leave=True)\n",
    "import math \n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl import edge_subgraph\n",
    "from dgl.nn.functional import edge_softmax\n",
    "import dgl.nn as dglnn\n",
    "import dgl.function as fn\n",
    "\n",
    "from GraphSage_Model import *\n",
    "from evaluation import *\n",
    "from inductive_graph import *\n",
    "from graph_to_dataframe import *\n",
    "from MLP_Model import *\n",
    "from print_func import *\n",
    "\n",
    "from MLP_run import *\n",
    "from catboost_run import *\n",
    "from GraphSage_run import *\n",
    "from GraphSage_featureless_run import *\n",
    "\n",
    "import functools\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import utils\n",
    "\n",
    "print(\"torch version is {}\".format(th.__version__))\n",
    "print(\"DGL version is {}\".format(dgl.__version__))\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    th.manual_seed(seed)\n",
    "    th.cuda.manual_seed_all(seed)\n",
    "    th.backends.cudnn.deterministic = True\n",
    "    th.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    dgl.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(CatBoost_LR=0.01, batch_size=1024, device_type='GPU', dropout=0.2, early_stopping=200, fanout=15, featureless_lr=0.0001, gpu=0, h_dim=64, iterations=3000, l2norm=0.001, loss_function='MultiClass', loss_weight=True, lr=0.001, n_epochs=1, num_bases=5, num_layers=1, num_worker=0, seed=101, train_test_split=0.1, use_self_loop=True, verbose=200)\n",
      "\n",
      "It took 11.2639 seconds to load graph\n",
      "\n",
      "The features associated with USAA Member are\n",
      " \n",
      "usaayr\n",
      "AGE_BAND\n",
      "ORIGEL\n",
      "ELIG2\n",
      "SEX\n",
      "MARST\n",
      "BRANCH\n",
      "ENLPAYGD\n",
      "MILST\n",
      "MLIST_OrigStat\n",
      "STATE\n",
      "\n",
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='RGCN')\n",
    "    parser.add_argument(\"--dropout\", type=float, default=0.2,\n",
    "            help=\"dropout probability\")\n",
    "    parser.add_argument(\"--h_dim\", type=int, default=64,\n",
    "            help=\"number of hidden units\")\n",
    "#     parser.add_argument(\"--out_dim\", type=int, default=1,\n",
    "#             help=\"output dimension\")\n",
    "    parser.add_argument(\"--gpu\", type=int, default=0,\n",
    "            help=\"gpu\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-3,\n",
    "            help=\"learning rate\")\n",
    "    parser.add_argument(\"--featureless_lr\", type=float, default=1e-4,\n",
    "            help='Learning Rate for featureless graph model')\n",
    "    parser.add_argument(\"--num_bases\", type=int, default=5,\n",
    "            help=\"number of filter weight matrices, default: -1 [use all]\")\n",
    "    parser.add_argument(\"--num_layers\", type=int, default=1,\n",
    "            help=\"number of propagation rounds\")\n",
    "    parser.add_argument(\"-e\", \"--n_epochs\", type=int, default=5,\n",
    "            help=\"number of training epochs\")\n",
    "#     parser.add_argument(\"--model_path\", type=str, default=\"/workspace/cjiang/eagle_project/CAP_graph/CAP_without_zipcode/rgcn_model_param.pt\",\n",
    "#             help='path for save the model')\n",
    "    parser.add_argument(\"--l2norm\", type=float, default=1e-3,\n",
    "            help=\"l2 norm coef\")\n",
    "    parser.add_argument(\"--use_self_loop\", default=True, action='store_true',\n",
    "            help=\"include self feature as a special relation\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=1024,\n",
    "            help=\"Mini-batch size. If -1, use full graph training.\")\n",
    "    parser.add_argument(\"--fanout\", type=int, default=15,\n",
    "            help=\"Fan-out of neighbor sampling.\")\n",
    "    parser.add_argument(\"--seed\",  type=int,default=101,\n",
    "            help=\"random seed for np.random.seed, torch.manual_seed and torch.cuda.manual_seed.\")\n",
    "    parser.add_argument(\"--loss_weight\",  type=bool,default=True,  ## number of label=0/number of label=1\n",
    "            help=\"weight for unbalance data\")\n",
    "    parser.add_argument(\"--num_worker\",  type=int,default=0,  \n",
    "            help=\"number of worker for neighbor sampling\") \n",
    "    parser.add_argument(\"--train_test_split\", type=float, default=0.1,\n",
    "            help=\"the proportion of test dataset\")\n",
    "    \n",
    "    parser.add_argument(\"--loss_function\", type=str, default=\"MultiClass\",\n",
    "            help='Loss function for Catboost')    \n",
    "    parser.add_argument(\"--CatBoost_LR\", type=float, default=0.01,\n",
    "            help='Learning Rate for Catboost')  \n",
    "    parser.add_argument(\"--iterations\", type=int, default=3000,\n",
    "            help='epochs iterations for Catboost')  \n",
    "    parser.add_argument(\"--early_stopping\", type=int, default=200,\n",
    "            help='early_stopping rounds for Catboost') \n",
    "    parser.add_argument(\"--device_type\", type=str, default=\"GPU\",\n",
    "            help='GPU utilization for Catboost training')      \n",
    "    parser.add_argument(\"--verbose\", type=int, default=200,\n",
    "            help='verbose details for Catboost training')  \n",
    "    \n",
    "    args,_=parser.parse_known_args()\n",
    "    \n",
    "    args.batch_size=1024\n",
    "    args.train_test_split=0.10\n",
    "    args.n_epochs=1\n",
    "    print(args)\n",
    "    print()\n",
    "    \n",
    "    seed_everything(args.seed)\n",
    "    \n",
    "    \n",
    "    KG_dir=\"/workspace/cjiang/eagle_project/CAP_graph/BGNN/\"\n",
    "\n",
    "    start=time.time()\n",
    "    with open(os.path.join(KG_dir,'CAP_Graph_v1'), 'rb') as f:\n",
    "        G,multi_label,binary_label,\\\n",
    "        train_mask_multi_label,  val_mask_multi_label,  test_mask_multi_label,\\\n",
    "        train_mask_binary_label, val_mask_binary_label, test_mask_binary_label= pickle.load(f)\n",
    "    end=time.time()\n",
    "    print(\"It took {:0.4f} seconds to load graph\".format(end-start))\n",
    "\n",
    "    usaanr_feat=[]\n",
    "    for key, scheme in G.node_attr_schemes(ntype=\"usaanr\").items():\n",
    "        usaanr_feat.append(key)\n",
    "\n",
    "    usaanr_feat=[x for x in usaanr_feat if x not in \n",
    "                 ['usaanr','cmpyelig','ACTCORP','Segment','train_mask','val_mask','test_mask','label','_ID']]\n",
    "\n",
    "    print()\n",
    "    print(\"The features associated with USAA Member are\\n \")\n",
    "    for i in usaanr_feat:\n",
    "        print(i)\n",
    "    print()\n",
    "    \n",
    "    G.nodes['usaanr'].data['label']=binary_label\n",
    "    \n",
    "    dict_edges={}\n",
    "    for etype in G.etypes:\n",
    "        dict_edges[etype]=th.arange(G.num_edges(etype))[0:2000]\n",
    "    sg=dgl.edge_subgraph(G,dict_edges)\n",
    "    G=copy.deepcopy(sg)\n",
    "    \n",
    "    subgraph_class=create_inductive_graph(G,args.train_test_split,args.seed)\n",
    "    train_g, test_g=subgraph_class.subgraph_func()\n",
    "    test_idx=subgraph_class.nodes_idx(train_g,test_g)\n",
    "    \n",
    "    assert train_g.num_nodes()+test_idx.shape[0]==test_g.num_nodes()\n",
    "    \n",
    "    device=\"cpu\"\n",
    "#     use_cuda=args.gpu>=0 and th.cuda.is_available()\n",
    "#     if use_cuda:\n",
    "#         th.cuda.set_device(args.gpu)\n",
    "#         device='cuda:%d' % args.gpu\n",
    "    \n",
    "    data=G, train_g, test_g, test_idx\n",
    "    \n",
    "    %pdb\n",
    "#     train_graph_v1, test_graph_v1=graph_run_featureless(args,usaanr_feat,device,data)    \n",
    "#     train_graph_v2, test_graph_v2=graph_run(args,usaanr_feat,device,data)\n",
    "#     train_catboost, test_catboost=catboost_run(args,device,data)\n",
    "#     train_mlp, test_mlp=MLP_run(args,usaanr_feat,device,data)\n",
    "    \n",
    "#     print()\n",
    "#     func_print(train_catboost, train_mlp, train_graph_v1, train_graph_v2, \"train_output.txt\")\n",
    "#     print()\n",
    "#     func_print(test_catboost, test_mlp, test_graph_v1, test_graph_v2, \"test_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set    22,302    \n",
      "test set        4,811     \n",
      "\n",
      "The number of minibatch in training set is 22\n",
      "The number of minibatch in test set is 5\n",
      "\n",
      "\n",
      "***************************************************************** \n",
      "========= Training Loop For Graph Model without feature ========= \n",
      "***************************************************************** \n",
      "\n",
      "\n",
      "========= Epoch 1 /1\n",
      "Training...\n",
      "Batch 2 of 22 | Loss 1.356  | Elapsed: 0:00:01\n",
      "Batch 4 of 22 | Loss 1.353  | Elapsed: 0:00:01\n",
      "Batch 6 of 22 | Loss 1.361  | Elapsed: 0:00:01\n",
      "Batch 8 of 22 | Loss 1.356  | Elapsed: 0:00:02\n",
      "Batch 10 of 22 | Loss 1.345  | Elapsed: 0:00:02\n",
      "Batch 12 of 22 | Loss 1.340  | Elapsed: 0:00:03\n",
      "Batch 14 of 22 | Loss 1.320  | Elapsed: 0:00:03\n",
      "Batch 16 of 22 | Loss 1.289  | Elapsed: 0:00:03\n",
      "Batch 18 of 22 | Loss 1.282  | Elapsed: 0:00:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 20 of 22 | Loss 1.277  | Elapsed: 0:00:04\n",
      "\n",
      "\n",
      "Running Validation on training set\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:01<00:00, 13.72it/s]\n",
      "100%|██████████| 1/1 [00:05<00:00,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss: 1.11 | True_Prediction: 11,354 | False_Prediction: 10,948 | accuracy: 50.91% |  precision: 43.26% | recall:         44.53% | F1_score: 43.89% | Gain_top-10%: 0.1 | ROC_AUC: 49.7% | PR_AUC: 43.0% | Elapsed: 0:00:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "G, train_g, test_g, test_idx=data\n",
    "\n",
    "train_idx=th.arange(train_g.num_nodes()).squeeze()       \n",
    "test_idx=th.from_numpy(test_idx).squeeze()\n",
    "\n",
    "train_label=train_g.nodes['usaanr'].data['label']\n",
    "test_label=test_g.nodes['usaanr'].data['label']\n",
    "\n",
    "label_train=train_label.squeeze().numpy()\n",
    "label_test=test_label.squeeze().numpy()\n",
    "\n",
    "print('{:<15} {:<10,}'.format(\"Training set\",train_idx.shape[0]))\n",
    "print('{:<15} {:<10,}'.format(\"test set\",test_idx.shape[0]))\n",
    "print()\n",
    "\n",
    "num_classes=th.unique(th.from_numpy(label_train)).shape[0]\n",
    "if args.loss_weight:\n",
    "    train_classes_num, train_classes_weight = get_class_count_weight(label_train,num_classes)\n",
    "    loss_weight=th.tensor(train_classes_weight).to(device)\n",
    "else:\n",
    "    loss_weight=None\n",
    "\n",
    "model = Entity_Classify_FeatureLess(G,\n",
    "                                    device,\n",
    "                                    args.h_dim,\n",
    "                                    num_classes,\n",
    "                                    num_bases=args.num_bases,\n",
    "                                    num_hidden_layers=args.num_layers,\n",
    "                                    dropout=args.dropout,\n",
    "                                    use_self_loop=args.use_self_loop)\n",
    "if device !=\"cpu\":\n",
    "    model.cuda()\n",
    "\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=args.featureless_lr, weight_decay=args.l2norm)\n",
    "\n",
    "# train sampler\n",
    "train_sampler = dgl.dataloading.MultiLayerNeighborSampler([args.fanout] * args.num_layers)\n",
    "train_loader = dgl.dataloading.NodeDataLoader(\n",
    "    train_g, {'usaanr': train_idx}, train_sampler,\n",
    "    batch_size=args.batch_size, shuffle=True, num_workers=args.num_worker)\n",
    "\n",
    "test_sampler = dgl.dataloading.MultiLayerNeighborSampler([args.fanout] * args.num_layers)\n",
    "test_loader = dgl.dataloading.NodeDataLoader(\n",
    "    test_g, {'usaanr': test_idx}, test_sampler,\n",
    "    batch_size=args.batch_size, shuffle=False, num_workers=args.num_worker)\n",
    "\n",
    "print(\"The number of minibatch in training set is {:,}\".format(len(train_loader)))\n",
    "print(\"The number of minibatch in test set is {:,}\".format(len(test_loader)))\n",
    "print()\n",
    "\n",
    "\n",
    "#### Training Loop\n",
    "print()\n",
    "print(\"***************************************************************** \")\n",
    "print(\"========= Training Loop For Graph Model without feature ========= \")\n",
    "print(\"***************************************************************** \")\n",
    "print()\n",
    "\n",
    "LOSS_EPOCH=[]\n",
    "LABEL_TRAIN=[]\n",
    "total_loss=0\n",
    "losses=[]\n",
    "LOGIT_train=[]\n",
    "LABEL_train=[]\n",
    "\n",
    "for epoch in tqdm(range(0,args.n_epochs)):\n",
    "\n",
    "    model.train()\n",
    "    IDX=[]\n",
    "    H=[]\n",
    "\n",
    "    #====================================#\n",
    "    #            Traning                 #\n",
    "    #====================================#\n",
    "    print(\"\")\n",
    "    print(\"========= Epoch {:} /{:}\".format(epoch+1,args.n_epochs))\n",
    "    print(\"Training...\")\n",
    "    t0 = time.time()\n",
    "    for step, (input_nodes_raw, seeds_raw, blocks) in enumerate(train_loader):\n",
    "        blocks = [blk.to(device) for blk in blocks]\n",
    "\n",
    "        seeds=seeds_raw.to(device)\n",
    "\n",
    "        labels_train=train_label[seeds].to(device)       \n",
    "\n",
    "        input_nodes={}\n",
    "        input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "        input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "\n",
    "        logits,h = model(train_g,input_nodes,blocks)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if args.loss_weight :\n",
    "            loss = F.cross_entropy(logits.view(-1, num_classes), \n",
    "                                   labels_train.squeeze().to(device),weight=loss_weight.float().to(device))\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits.view(-1, num_classes), labels_train.squeeze().to(device))\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        arg1=logits[:,1].detach().cpu().numpy()\n",
    "        arg2=labels_train.cpu().numpy()\n",
    "\n",
    "        train_gain = lift_gain_eval(arg1,arg2,topk=[0.01,0.05,0.10])\n",
    "\n",
    "        train_acc = th.sum(logits.argmax(dim=1) == labels_train).item() / len(seeds)\n",
    "        precision, recall, fscore, support = precision_recall_fscore_support(labels_train.cpu().numpy(), \n",
    "                                                                             logits.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "        try:\n",
    "            train_auc = roc_auc_score(labels_train.detach().cpu().numpy().ravel(), th.sigmoid(logits)\\\n",
    "                                      [:,1].detach().cpu().numpy().ravel())\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        prec,rec,_ = precision_recall_curve(labels_train.detach().cpu().numpy().ravel(), th.sigmoid(logits)\\\n",
    "                                            [:,1].detach().cpu().numpy().ravel())\n",
    "        if math.isnan(rec[0])==False:\n",
    "            train_pr_auc=auc_score(rec,prec)\n",
    "\n",
    "        IDX.extend(seeds.detach().cpu().numpy().tolist())\n",
    "        H.extend(h[\"usaanr\"].detach().cpu().numpy().tolist())\n",
    "        LOGIT_train.extend(logits.detach().cpu().numpy().tolist())\n",
    "        LABEL_train.extend(train_label[blocks[-1].dstnodes['usaanr'].data[dgl.NID].cpu().numpy()].tolist())\n",
    "\n",
    "        if step%(len(train_loader)//10)==0 and not step==0:\n",
    "\n",
    "            t1 = time.time()\n",
    "            elapsed=utils.format_time(t1-t0)\n",
    "            print(\"Batch {:} of {:} | Loss {:.3f}  | Elapsed: {:}\".\\\n",
    "                  format(step,len(train_loader),np.mean(losses[-10:]),elapsed)) \n",
    "\n",
    "    LOSS_EPOCH.append(loss)\n",
    "\n",
    "    LABEL_TRAIN.append(train_label[blocks[-1].nodes['usaanr'].data[dgl.NID].cpu().numpy()])\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    print()\n",
    "    print(\"\")\n",
    "    print(\"Running Validation on training set\")\n",
    "    print(\"\")\n",
    "    fin_outputs, fin_targets, losses_tmp=eval_loop_func(train_g, model, train_loader, train_label,  device, loss_weight, num_classes)\n",
    "\n",
    "    avg_loss_train=np.mean(losses_tmp)\n",
    "\n",
    "    tmp_mean_pool_train=evaluate(fin_targets.reshape(-1),fin_outputs)\n",
    "\n",
    "    t2=time.time()\n",
    "\n",
    "    print(\"avg_loss: {:.2f} | True_Prediction: {:,} | False_Prediction: {:,} | accuracy: {:.2%} |  precision: {:.2%} | recall: \\\n",
    "        {:.2%} | F1_score: {:.2%} | Gain_top-10%: {:.1f} | ROC_AUC: {:.1%} | PR_AUC: {:.1%} | Elapsed: {:}\".format(avg_loss_train, \n",
    "          tmp_mean_pool_train[\"true_prediction\"], tmp_mean_pool_train[\"false_prediction\"], tmp_mean_pool_train[\"accuracy\"], \\\n",
    "          tmp_mean_pool_train[\"precision\"], tmp_mean_pool_train[\"recall\"],tmp_mean_pool_train[\"f1_score\"], \\\n",
    "          tmp_mean_pool_train[\"GAIN\"]['10%'], tmp_mean_pool_train[\"AUC\"],tmp_mean_pool_train[\"pr_auc\"],utils.format_time(t2-t1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-75b24bc96505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfin_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfin_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_tmp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_loop_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/inductive_learning/evaluation.py\u001b[0m in \u001b[0;36meval_loop_func\u001b[0;34m(g, model, loader, labels, device, loss_weight, num_classes)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloss_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/inductive_learning/GraphSage_Model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sg, input_nodes, blocks)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mntype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mnid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_embed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mntype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblocks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/inductive_learning/GraphSage_Model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sg, nid)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#         self.emb=self.emb.to(\"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usaanr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mout_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usaanr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m         return F.embedding(\n\u001b[1;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1850\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m(1852)\u001b[0;36membedding\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m   1850 \u001b[0;31m        \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1851 \u001b[0;31m        \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m-> 1852 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1853 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m   1854 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/sparse.py\u001b[0m(126)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    124 \u001b[0;31m        return F.embedding(\n",
      "\u001b[0m\u001b[0;32m    125 \u001b[0;31m            \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 126 \u001b[0;31m            self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0m\u001b[0;32m    127 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    128 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m(727)\u001b[0;36m_call_impl\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    725 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    726 \u001b[0;31m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 727 \u001b[0;31m            \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    728 \u001b[0;31m        for hook in itertools.chain(\n",
      "\u001b[0m\u001b[0;32m    729 \u001b[0;31m                \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  u\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/workspace/cjiang/eagle_project/CAP_graph/inductive_learning/GraphSage_Model.py\u001b[0m(37)\u001b[0;36mforward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     35 \u001b[0;31m\u001b[0;31m#         self.emb=self.emb.to(\"cpu\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     36 \u001b[0;31m        \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usaanr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdgl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 37 \u001b[0;31m        \u001b[0mout_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usaanr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     39 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mout_feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1203])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  idx.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22033712)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  self.emb['usaanr'].weight.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([27114, 64])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  nid.shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1203])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  nid.max()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22205)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  q\n"
     ]
    }
   ],
   "source": [
    "fin_outputs, fin_targets, losses_tmp=eval_loop_func(test_g, model, test_loader, test_label,  device, loss_weight, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# fin_targets=[]\n",
    "# fin_outputs=[]\n",
    "# losses=[]\n",
    "# input_nodes_raw, seeds_raw, blocks =next(iter(test_loader))\n",
    "\n",
    "# blocks = [blk.to(device) for blk in blocks]\n",
    "# seeds = seeds_raw.to(device)\n",
    "\n",
    "# input_nodes={}\n",
    "# input_nodes[\"usaanr\"]=input_nodes_raw\n",
    "# input_nodes={k : e.to(device) for k, e in input_nodes.items()}\n",
    "\n",
    "# lbl = labels[seeds].squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'usaanr': 27113},\n",
       "      num_edges={('usaanr', 'AUTO_RELATED', 'usaanr'): 2000, ('usaanr', 'Brother_Sister', 'usaanr'): 2000, ('usaanr', 'Busi_rel_Other', 'usaanr'): 2000, ('usaanr', 'Child', 'usaanr'): 2000, ('usaanr', 'Ex-Spouse', 'usaanr'): 2000, ('usaanr', 'Parent', 'usaanr'): 2000, ('usaanr', 'Pers_rel_Other', 'usaanr'): 2000, ('usaanr', 'SPONSEE', 'usaanr'): 2000, ('usaanr', 'SPONSOR', 'usaanr'): 2000, ('usaanr', 'Spouse', 'usaanr'): 2000, ('usaanr', 'Step-Child', 'usaanr'): 2000, ('usaanr', 'Step-Parent', 'usaanr'): 2000},\n",
       "      metagraph=[('usaanr', 'usaanr', 'AUTO_RELATED'), ('usaanr', 'usaanr', 'Brother_Sister'), ('usaanr', 'usaanr', 'Busi_rel_Other'), ('usaanr', 'usaanr', 'Child'), ('usaanr', 'usaanr', 'Ex-Spouse'), ('usaanr', 'usaanr', 'Parent'), ('usaanr', 'usaanr', 'Pers_rel_Other'), ('usaanr', 'usaanr', 'SPONSEE'), ('usaanr', 'usaanr', 'SPONSOR'), ('usaanr', 'usaanr', 'Spouse'), ('usaanr', 'usaanr', 'Step-Child'), ('usaanr', 'usaanr', 'Step-Parent')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27114, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed=nn.Embedding(G.num_nodes(\"usaanr\")+1, 5)\n",
    "embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=test_g.nodes['usaanr'].data[dgl.NID][th.tensor([4857,800842])].squeeze().to(self.device)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
